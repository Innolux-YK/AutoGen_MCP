"""
èŠå¤©é¦–é ï¼ˆHomeï¼‰ã€‚
ä½¿ç”¨å®˜æ–¹å¤šé çµæ§‹ï¼šæ­¤æª”ç‚ºé¦–é ï¼Œå·¦å´å°‡è‡ªå‹•åˆ—å‡º pages/ å…§ä¿ç•™çš„é é¢ï¼ˆå¦‚ ç‹€æ…‹/é—œæ–¼ï¼‰ã€‚
"""
from __future__ import annotations

import os
import sys
from datetime import datetime

import streamlit as st

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ sys.pathï¼ˆä¾›å­é é¢å¼•ç”¨ï¼‰
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from frontend.app_init import (
    ensure_session_init,
    get_current_conversation,
    update_conversation_title,
    create_new_conversation,
    delete_conversation,
)
from frontend.ui_helpers import (
    create_unique_images_list,
    create_unique_documents_list,
    open_file_with_system,
    display_message,
)
import config

# é é¢é…ç½®ï¼ˆHomeï¼‰
st.set_page_config(
    page_title="ğŸ’¬ AIåŠ©æ‰‹",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è‡ªå®šç¾©CSSï¼šæ¸›å°‘æ¨™é¡Œä¸Šæ–¹ç©ºç™½
st.markdown("""
<style>
    .main .block-container {
        padding-top: 20px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ’¬ AIåŠ©æ‰‹")

# åˆå§‹åŒ–ç‹€æ…‹
ensure_session_init()
current_conv = get_current_conversation()

# å´é‚Šæ¬„ï¼šç¾åŒ–çš„å°è©±ç®¡ç†æŠ½å±œï¼ˆä¸æ³¨å…¥å…¨åŸŸ CSSï¼‰
with st.sidebar:
    st.markdown("## ğŸ—‚ï¸ å°è©±ç®¡ç†")
    with st.container(border=True):
        c1, c2 = st.columns(2)
        with c1:
            if st.button("â• æ–°å°è©±", use_container_width=True):
                create_new_conversation()
                st.rerun()
        with c2:
            if st.button("ğŸ—‘ï¸ åˆªé™¤ç›®å‰", use_container_width=True):
                delete_conversation(current_conv["id"])
                st.rerun()

        # å¿«é€Ÿéæ¿¾
        q = st.text_input("æœå°‹å°è©±æ¨™é¡Œ", value=st.session_state.get("conv_filter", ""), placeholder="è¼¸å…¥é—œéµå­—â€¦")
        st.session_state.conv_filter = q

        conversations = st.session_state.conversations
        conv_items = sorted(
            conversations.values(),
            key=lambda x: x.get("updated_at", x.get("created_at", "")),
            reverse=True,
        )
        if q:
            conv_items = [c for c in conv_items if q.lower() in c.get("title", "").lower()]

        options = [c["id"] for c in conv_items]

        def label_func(cid: str) -> str:
            conv = conversations.get(cid, {})
            title = conv.get("title", "æ–°å°è©±")
            msgs = len(conv.get("messages", []))
            t = conv.get("updated_at") or conv.get("created_at") or ""
            t_disp = t.replace("T", " ")[:16] if t else ""
            return f"{title} Â· {msgs} è¨Šæ¯ Â· {t_disp}"

        if options:
            current_index = options.index(current_conv["id"]) if current_conv["id"] in options else 0
            selected_id = st.selectbox(
                "é¸æ“‡å°è©±",
                options=options,
                index=current_index,
                format_func=label_func,
            )
            if selected_id != current_conv["id"]:
                st.session_state.current_conversation_id = selected_id
                st.rerun()
        else:
            st.caption("å°šç„¡å°è©±ï¼Œè«‹å»ºç«‹æ–°å°è©±ã€‚")

    st.markdown("---")
    with st.expander("âš™ï¸ ç³»çµ±æ“ä½œ"):
        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸ§¹ æ¸…ç©ºå°è©±", key="clear_conv"):
                current_conv["messages"] = []
                current_conv["chat_history"] = []
                current_conv["updated_at"] = datetime.now().isoformat()
                st.rerun()
        with c2:
            if st.button("ğŸ”„ é‡æ–°è¼‰å…¥", key="reload_app"):
                st.rerun()

# ä¸»è¦æ§åˆ¶åˆ—
col1, col2, col3, col4 = st.columns([1.5, 2, 2.5, 1.5])

with col1:
    # å¾ config.py è®€å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = config.get_available_models()
    default_model = config.INNOAI_DEFAULT_MODEL
    
    # ç¢ºä¿é»˜èªæ¨¡å‹åœ¨åˆ—è¡¨ä¸­ï¼Œå¦‚æœä¸åœ¨å‰‡ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨æ¨¡å‹
    if default_model not in available_models:
        default_model = available_models[0] if available_models else "gpt-4.1"
    
    default_index = available_models.index(default_model) if default_model in available_models else 0
    
    llm_model = st.selectbox(
        "LLM æ¨¡å‹",
        options=available_models,
        index=default_index,
        key="llm_model",
        help="é¸æ“‡è¦ä½¿ç”¨çš„èªè¨€æ¨¡å‹",
    )

with col2:
    # ä¿æŒç”¨æˆ¶çš„å•é¡Œè™•ç†æ–¹å¼é¸æ“‡
    default_query_mode = st.session_state.get("query_mode_selection", "è©¢å•å•é¡Œ")
    default_query_index = 0 if default_query_mode == "è©¢å•å•é¡Œ" else 1
    
    query_mode = st.selectbox(
        "å•é¡Œè™•ç†æ–¹å¼",
        options=["è©¢å•å•é¡Œ", "å°‹æ‰¾çœŸå› "],
        index=default_query_index,
        key="query_mode",
        help="è©¢å•å•é¡Œï¼šå¾çŸ¥è­˜åº«æœå°‹ç­”æ¡ˆã€‚\nå°‹æ‰¾çœŸå› ï¼šä½¿ç”¨ Agent/å·¥å…·åˆ†æã€‚",
    )
    
    # ä¿å­˜ç”¨æˆ¶çš„é¸æ“‡
    st.session_state.query_mode_selection = query_mode

with col3:
    new_title = st.text_input(
        "å°è©±æ¨™é¡Œ",
        value=current_conv["title"],
        key="conv_title",
        help="é»æ“Šç·¨è¼¯å°è©±æ¨™é¡Œ",
    )
    if new_title != current_conv["title"]:
        update_conversation_title(current_conv["id"], new_title)

with col4:
    # åœ¨æ¨™ç±¤ä¸Šæ–¹æ·»åŠ ç©ºç™½ï¼Œä½¿æŒ‰éˆ•èˆ‡å…¶ä»–è¼¸å…¥æ¡†å°é½Š
    st.markdown('<div style="height: 20px;"></div>', unsafe_allow_html=True)
    
    # æŒ‰éˆ•ç¾¤çµ„ï¼šæ”¾åœ¨åŒä¸€åˆ—ä¸­
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ—‘ï¸", help="æ¸…ç©ºç•¶å‰å°è©±", key="clear_main", use_container_width=True):
            current_conv["messages"] = []
            current_conv["chat_history"] = []
            current_conv["updated_at"] = datetime.now().isoformat()
            st.rerun()
    with c2:
        if st.button("ğŸ”„", help="é‡æ–°è¼‰å…¥é é¢", key="reload_main", use_container_width=True):
            st.rerun()

st.divider()

# é¡¯ç¤ºæ­·å²è¨Šæ¯
# å§‹çµ‚é¡¯ç¤ºæç¤ºç¯„ä¾‹
if query_mode == "è©¢å•å•é¡Œ":
    example_text = """ğŸ’¡ è©¦è©¦å•æˆ‘ï¼š
1. ã€ŒSPCæ²’é€²ChartæŸ¥æ‰¾æ–¹æ³•ã€
2. ã€ŒEDCä¸Šå‚³æª”æ¡ˆæ ¼å¼ã€"""
else:
    example_text = """ğŸ’¡ è©¦è©¦å•æˆ‘ï¼š
1. ã€Œä½ æœ‰å“ªäº›åŠŸèƒ½ã€
2. ã€ŒSPCç‚ºä»€éº¼æ²’æœ‰é€²CHARTã€
3. ã€ŒEDCæª”æ¡ˆæ ¼å¼ç¢ºèªã€
4. ã€ŒIP EDCæŸ¥æ‰¾ã€"""

st.info(example_text)

for message in current_conv["messages"]:
    display_message(message)

# è™•ç† pending æŸ¥è©¢ï¼ˆä¸²æµï¼‰
if st.session_state.get("pending_query"):
    payload = st.session_state.get("pending_query")
    with st.status("ğŸ¤– æ­£åœ¨è™•ç†æ‚¨çš„å•é¡Œ...", expanded=False) as status:
        try:
            query_type_display = "çŸ¥è­˜åº«æœå°‹" if payload["force_query_type"] == "rag_search" else "æ™ºèƒ½å·¥å…·åˆ†æ"
            st.write(f"ğŸ” åˆ†æå•é¡Œé¡å‹: {query_type_display}")
            st.write("âš™ï¸ åˆå§‹åŒ–AIè™•ç†å™¨...")
            st.write("ğŸ“ ç”Ÿæˆå›æ‡‰...")
            status.update(label="âœ… è™•ç†å®Œæˆï¼æ­£åœ¨é¡¯ç¤ºå›æ‡‰...", state="complete", expanded=False)
        except Exception as e:
            st.write(f"âŒ è™•ç†å¤±æ•—: {str(e)}")
            status.update(label="âŒ è™•ç†å¤±æ•—", state="error", expanded=True)
            st.session_state.pop("pending_query", None)
            st.rerun()

    response_container = st.container()
    with response_container:
        with st.chat_message("assistant"):
            response_data_holder = [None]

            def response_generator():
                for chunk in st.session_state.conversation_manager.get_response_stream(
                    payload["q"],
                    current_conv["chat_history"],
                    force_query_type=payload["force_query_type"],
                    llm_model=payload.get("llm_model", "gpt-4.1"),
                ):
                    if isinstance(chunk, dict) and "__FINAL_RESPONSE__" in chunk:
                        response_data_holder[0] = chunk["__FINAL_RESPONSE__"]
                    else:
                        yield chunk

            response_text = st.write_stream(response_generator())
            full_response_data = response_data_holder[0]
            st.caption(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}")

            if full_response_data:
                images = full_response_data.get("images") or []
                if images:
                    unique_images = create_unique_images_list(images)
                    if unique_images:
                        st.markdown("**ğŸ“¸ ç›¸é—œåœ–ç‰‡ï¼š**")
                        
                        # ä½¿ç”¨tabsä¾†é¡¯ç¤ºåœ–ç‰‡ï¼Œä¾¿æ–¼åˆ‡æ›å’Œæ”¾å¤§è§€çœ‹
                        img_tabs = st.tabs([f"åœ–ç‰‡ {i+1}" for i in range(len(unique_images[:3]))])
                        
                        for i, img_path in enumerate(unique_images[:3]):
                            try:
                                with img_tabs[i]:
                                    # åœ–ç‰‡åç¨±
                                    st.caption(f"ï¿½ {os.path.basename(img_path)}")
                                    # å¯æ”¾å¤§çš„åœ–ç‰‡é¡¯ç¤ºï¼ˆä¿®æ­£æ£„ç”¨è­¦å‘Šï¼‰
                                    st.image(img_path, use_container_width=True)
                            except Exception as e:
                                st.error(f"ç„¡æ³•é¡¯ç¤ºåœ–ç‰‡ {i+1}: {e}")


                docs = full_response_data.get("source_documents") or []
                if docs:
                    unique_docs = create_unique_documents_list(docs)
                    if unique_docs:
                        with st.expander("ğŸ“„ æŸ¥çœ‹ç›¸é—œæ–‡æª”ä¾†æº", expanded=False):
                            for i, doc in enumerate(unique_docs[:3]):
                                col1, col2 = st.columns([4, 1])
                                with col1:
                                    st.markdown(
                                        f"""
                                    **ğŸ“„ æ–‡æª” {i+1}**  
                                    **æª”æ¡ˆ:** {doc.get('source_file','Unknown')}  
                                    **æ¨™é¡Œ:** {doc.get('title','No title')}  
                                    **å…§å®¹é è¦½:** {doc.get('content','')[:150]}...
                                    """
                                    )
                                with col2:
                                    file_path = ""
                                    if "metadata" in doc and isinstance(doc["metadata"], dict):
                                        file_path = doc["metadata"].get("file_path", "")
                                    elif "file_path" in doc:
                                        file_path = doc["file_path"]

                                    if file_path and os.path.exists(file_path):
                                        if st.button(
                                            f"ğŸ“‚ é–‹å•Ÿ",
                                            key=f"open_doc_{i}_{id(file_path)}_{hash(str(doc))}",
                                            help=f"é–‹å•ŸåŸå§‹æª”æ¡ˆ: {os.path.basename(file_path)}",
                                        ):
                                            if open_file_with_system(file_path):
                                                st.success(f"å·²é–‹å•Ÿ: {os.path.basename(file_path)}")
                                    else:
                                        st.caption("æª”æ¡ˆè·¯å¾‘ä¸å¯ç”¨")

                                if i < len(unique_docs) - 1:
                                    st.divider()

    if full_response_data:
        current_conv["messages"].append(
            {
                "role": "assistant",
                "content": response_text,
                "images": full_response_data.get("images", []),
                "source_documents": full_response_data.get("source_documents", []),
                "query_type": full_response_data.get("query_type", "unknown"),
                "confidence": full_response_data.get("confidence", 0.0),
                "time": datetime.now().strftime("%Y-%m-%d %H:%M"),
            }
        )
    else:
        current_conv["messages"].append(
            {
                "role": "assistant",
                "content": response_text,
                "time": datetime.now().strftime("%Y-%m-%d %H:%M"),
            }
        )

    current_conv["chat_history"].extend(
        [
            {"role": "user", "content": payload["q"]},
            {"role": "assistant", "content": response_text},
        ]
    )

    if current_conv["title"] == "æ–°å°è©±" and len(current_conv["messages"]) == 2:
        first_question = payload["q"][:30] + ("..." if len(payload["q"]) > 30 else "")
        update_conversation_title(current_conv["id"], first_question)

    current_conv["updated_at"] = datetime.now().isoformat()
    st.session_state.pop("pending_query", None)
    st.rerun()

# åº•éƒ¨è¼¸å…¥
user_prompt = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...")
if user_prompt and user_prompt.strip():
    q = user_prompt.strip()
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    force_query_type = "rag_search" if query_mode == "è©¢å•å•é¡Œ" else "agent"

    current_conv["messages"].append({"role": "user", "content": q, "time": now})
    st.session_state["pending_query"] = {
        "q": q, 
        "force_query_type": force_query_type, 
        "llm_model": llm_model,
        "time": now
    }
    st.rerun()
