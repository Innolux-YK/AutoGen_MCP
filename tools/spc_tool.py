"""
SPC ç³»çµ±è¨ºæ–·å·¥å…· ï¼Œé€™æ®µä¸è¦æ‹¿æ‰

ä»¥ä¸‹ç‚ºè©²å·¥å…·çš„å®Œæ•´æŸ¥è©¢é‚è¼¯ã€‚
FACTORY_MAP = {
    "TFT6": {"path": "TFT6", "svr": "APCSPCDT", "sql_table": "ASPC_ONLNCHART", "mes_schema": "T6WPT1A1", "data_schema": "T6HEC1D", "para_table": "HAMSPARA", "glsinfo_table": "HAMSGLSINFO", "raw_table": "HAMSRAW"},
    "CF6": {"path": "CF6", "svr": "BPCSPCDT", "sql_table": "BSPC_ONLNCHART", "mes_schema": "F6WPT1A1", "data_schema": "F6HEC1D", "para_table": "HBMSPARA", "glsinfo_table": "HBMSGLSINFO", "raw_table": "HBMSRAW"},
    "LCD6": {"path": "LCD6", "svr": "CPCSPCDT", "sql_table": "CSPC_ONLNCHART", "mes_schema": "L6WPT1A1", "data_schema": "L6HEC1D", "para_table": "HCMSPARA", "glsinfo_table": "HCMSGLSINFO", "raw_table": "HCMSRAW"},
    "USL": {"path": "USL", "svr": "CPCMSRDT", "sql_table": "CSPC_ONLNCHART", "mes_schema": "U3WPT1A1", "data_schema": "U3REC1D", "para_table": "HCMSPARA", "glsinfo_table": "HCMSGLSINFO", "raw_table": "HCMSRAW"},
}

æŸ¥è©¢æ­¥é©Ÿï¼š
1. å¾ç”¨æˆ¶æŸ¥è©¢ä¸­æå–é—œéµè³‡è¨Šï¼ˆå» åˆ¥ã€æ™‚é–“ã€ç»ç’ƒIDã€è¨­å‚™IDã€CHART IDï¼‰
2. æª¢æŸ¥æ˜¯å¦æä¾›å¿…è¦çš„äº”å€‹æ¢ä»¶
3. å¦‚æœè³‡è¨Šå®Œæ•´ï¼Œé€²è¡Œå¯¦éš›æŸ¥è©¢
4. æŸ¥è©¢TRX LOGï¼Œå…ˆæŸ¥http://tncimweb.cminl.oa/Apigateway/MesLogApi/TFT6/trx-log?fromDT=&toDT=&svrModules=APCSPCDT&shtId=&eqptId=&lastTStamp=&pageSize=2
å…¶ä¸­TFT6ç‚ºå» åˆ¥ä»£ç¢¼ï¼ŒfromDTå’ŒtoDTç‚ºæ™‚é–“ç¯„åœ(ä½¿ç”¨USERå‚³å…¥çš„æ™‚é–“å‰å¾ŒåŠå°æ™‚)ï¼ŒsvrModulesç‚ºç•¶TFT6æ™‚ç‚ºAPCSPCDTï¼Œç•¶CF6æ™‚ç‚ºBPCSPCDTï¼Œç•¶LCD6/USLæ™‚ç‚ºCPCSPCDTï¼ŒshtIdç‚ºç»ç’ƒIDï¼ŒeqptIdç‚ºè¨­å‚™ID
5. å¦‚æœåªæœ‰æŸ¥åˆ°ä¸€ç­†ï¼Œè¡¨ç¤ºæ™‚é–“æº–ç¢ºï¼Œè‹¥æŸ¥åˆ°å¤šç­†ï¼Œè¡¨ç¤ºæ™‚é–“ç¯„åœéå¤§ï¼Œè«‹ç”¨æˆ¶æä¾›æ›´ç²¾ç¢ºçš„æ™‚é–“ã€‚
6. æ¥è‘—æŸ¥è©¢http://tncimweb.cminl.oa/Apigateway/MesLogApi/TFT6/trx-log?fromDT=2025%2F08%2F25%2013%3A11%3A38&toDT=2025%2F08%2F25%2014%3A11%3A38&svrModules=APCSPCDT&lastTStamp=&pageSize=1
å…¶ä¸­TFT6ç‚ºå» åˆ¥ä»£ç¢¼ï¼ŒfromDTå’ŒtoDTèˆ‡ä¸Šæ­¥æŸ¥è©¢ç›¸åŒ)ï¼ŒsvrModulesç‚ºç•¶TFT6æ™‚ç‚ºAPCSPCDTï¼Œç•¶CF6æ™‚ç‚ºBPCSPCDTï¼Œç•¶LCD6/USLæ™‚ç‚ºCPCSPCDT
7. æ¥è‘—æŸ¥è©¢http://tncimweb.cminl.oa/Apigateway/MesLogApi/TFT6/trx-log/APCSPCDT/2025-08-25-14.11.37.556813?ignoreBody=false
å…¶ä¸­TFT6ç‚ºå» åˆ¥ä»£ç¢¼ï¼ŒsvrModulesç‚ºç•¶TFT6æ™‚ç‚ºAPCSPCDTï¼Œç•¶CF6æ™‚ç‚ºBPCSPCDTï¼Œç•¶LCD6/USLæ™‚ç‚ºCPCSPCDTï¼Œ2025-08-25-14.11.37.556813ç‚ºä¸Šä¸€æ­¥æŸ¥åˆ°çš„tStamp
8. é€™é‚ŠTRX LOGæŸ¥è©¢çµæŸã€‚UIé¡¯ç¤ºå‘ŠçŸ¥USERã€‚
9. æ¥è‘—æŸ¥è©¢DBè³‡æ–™ã€‚é€éAPIæŸ¥è©¢SPC DBï¼Œsql = SELECT * FROM {data_schema}.{glsinfo_table} a 
        inner join
    {data_schema}.{para_table} b
        on a.SEQ = b.SEQ
        inner join 
    {data_schema}.{raw_table} c
        on (b.SEQ = c.SEQ AND b.data_group = c.data_group)
WHERE  a.SHT_ID ='{sht}';"
10. å¦‚æœæœ‰æ‰¾åˆ°è³‡æ–™ï¼Œè¡¨ç¤ºæœ‰è³‡æ–™é€²CHARTï¼Œå°±åœæ­¢å‹•ä½œã€‚å‘ŠçŸ¥USERè©²ç­†è³‡æ–™æœ‰é€²CHARTã€‚
11. è‹¥æ²’æ‰¾åˆ°è³‡æ–™ï¼Œè¡¨ç¤ºæ²’æœ‰é€²CHARTã€‚é€™æ™‚å€™å°‡CHARTçš„è³‡æ–™èª¿å‡ºä¾†é¡¯ç¤ºçµ¦USERçœ‹ã€‚æŸ¥è©¢MES DBã€‚SQL = SELECT * FROM ASPC_ONLNCHART WHERE ONCHID = ''
å…¶ä¸­TFT6ç‚ºASPC_ONLNCHARTï¼ŒCF6ç‚ºBSPC_ONLNCHARTï¼ŒLCD6/USLç‚ºCSPC_ONLNCHARTï¼ŒONCHIDç‚ºç”¨æˆ¶æä¾›çš„CHART ID
12. æ¥è‘—æ ¹æ“šç¬¬6æ­¥æŸ¥è©¢åˆ°çš„è³‡æ–™åˆ†æå‡ºChart_Conditionå­—ä¸²ï¼Œå¾Œé¢ç‚ºSQLçš„WHEREæ¢ä»¶ã€‚æŸ¥è©¢MES DBã€‚SQL = SELECT * FROM ASPC_ONLNCHART WHERE + Chart_Conditionå­—ä¸²å¾Œé¢å­—ä¸²ã€‚é€™é‚Šè¦å…¨éƒ¨æŸ¥è©¢ä¸è¦é™åˆ¶ç­†æ•¸ã€‚
13. æ¯”å°æŸ¥å‡ºä¾†çš„è³‡æ–™æ˜¯å¦æœ‰åœ¨ç¬¬11æ­¥æŸ¥è©¢åˆ°çš„CHARTä¸­ã€‚å¦‚æœæ²’æœ‰è¡¨ç¤ºæ¢ä»¶ä¸ç¬¦ã€‚
14. æ¥è‘—æ¯”å°ç¬¬11æ­¥æŸ¥åˆ°çš„CHARTæ‰€æœ‰æ¬„ä½èˆ‡ç¬¬12æ­¥åˆ†æå‡ºçš„WHEREæ¢ä»¶å…§çš„æ¬„ä½è³‡è¨Šæ˜¯å¦æœ‰ä¸ç¬¦çš„åœ°æ–¹ã€‚
15. å¦‚æœ‰ä¸ç›¸ç¬¦çš„åœ°æ–¹å°±æ˜¯å•é¡Œæ‰€åœ¨ã€‚
16. æ¯”å°ç¬¬9æ­¥æŸ¥åˆ°è³‡æ–™ä¸­çš„DATA_GROUPæ¬„ä½æ•¸å€¼æ˜¯å¦å­˜åœ¨MES DBä¸­ã€‚SQL = SELECT * FROM T6WPT1D.AMLITEM WHERE EQPT_ID='' AND REP_UNIT='' AND DATA_PAT='' AND MES_ID='' AND DATA_GROUP=''
TFT6:AMLITEMï¼ŒCF6:BMLITEMï¼ŒLCD6/USL:CMLITEMã€‚EQPT_IDï¼ŒREP_UNITï¼ŒDATA_PATï¼ŒMES_IDå¾ç¬¬12æ­¥æŸ¥åˆ°å¾Œé¢ç‚ºSQLçš„WHEREæ¢ä»¶å–å¾—ã€‚
    å¦‚æœæ²’æœ‰å°±æ˜¯å›ç­”USER:XMLITEM DBç¼ºå°‘è¨­å®šä¸Šå ±DATA_GROUP
17. æ¯”å°ç¬¬9æ­¥æŸ¥åˆ°è³‡æ–™ä¸­çš„DATA_GROUPæ¬„ä½æ•¸å€¼æ˜¯å¦å­˜åœ¨ç¬¬7æ­¥æŸ¥åˆ°çš„INPUTä¸­data_groupæ¨™ç±¤æ•¸å€¼ã€‚
    å¦‚æœæ²’æœ‰å°±æ˜¯å›ç­”USER:ç¼ºå°‘å¿…è¦ä¸Šå ±DATA_GROUP
18. å°‡ä¸ç›¸åŒä¹‹è™•ç¸½çµçµ¦USERã€‚


TEST:
æœ‰é€²CHART: å» åˆ¥:TFT6ï¼Œä¸Šå ±æ™‚é–“:2025-09-03-09.40.00ï¼Œç»ç’ƒID:T65913Y7ADï¼Œè¨­å‚™ID:IMRV0100ï¼ŒCHART ID:SPDV1400_2353_TOTAL
æ²’é€²CHART:
"""

import sys
import os
import re
import json
import requests
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from urllib.parse import quote

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from tools.base_tool import BaseTool
from apis.universal_query_api import execute_query

class SPCTool(BaseTool):
    """SPC ç³»çµ±è¨ºæ–·å·¥å…·"""
    
    def __init__(self):
        super().__init__()
        self.factory_map = {
            "TFT6": {"path": "TFT6", "svr": "APCSPCDT", "sql_table": "ASPC_ONLNCHART", "mes_schema": "T6WPT1D", "data_schema": "T6HEC1D", "para_table": "HAMSPARA", "glsinfo_table": "HAMSGLSINFO", "raw_table": "HAMSRAW", "mlitem_table": "AMLITEM"},
            "CF6": {"path": "CF6", "svr": "BPCSPCDT", "sql_table": "BSPC_ONLNCHART", "mes_schema": "F6WPT1D", "data_schema": "F6HEC1D", "para_table": "HBMSPARA", "glsinfo_table": "HBMSGLSINFO", "raw_table": "HBMSRAW", "mlitem_table": "BMLITEM"},
            "LCD6": {"path": "LCD6", "svr": "CPCSPCDT", "sql_table": "CSPC_ONLNCHART", "mes_schema": "L6WPT1D", "data_schema": "L6HEC1D", "para_table": "HCMSPARA", "glsinfo_table": "HCMSGLSINFO", "raw_table": "HCMSRAW", "mlitem_table": "CMLITEM"},
            "USL": {"path": "USL", "svr": "CPCMSRDT", "sql_table": "CSPC_ONLNCHART", "mes_schema": "U3WPT1D", "data_schema": "U3REC1D", "para_table": "HCMSPARA", "glsinfo_table": "HCMSGLSINFO", "raw_table": "HCMSRAW", "mlitem_table": "CMLITEM"},
        }
        self.base_url = "http://tncimweb.cminl.oa/Apigateway"
        
        # åˆå§‹åŒ–è©³ç´°è³‡æ–™æŸ¥çœ‹å·¥å…·
        self.detail_viewer = None
        try:
            from .spc_detail_viewer_tool import SPCDetailViewerTool
            self.detail_viewer = SPCDetailViewerTool()
        except ImportError:
            pass
    
    def _is_safe_identifier(self, value: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºå®‰å…¨çš„è­˜åˆ¥ç¬¦ï¼ˆé˜²æ­¢ SQL injectionï¼‰"""
        if not value or not isinstance(value, str):
            return False
        # å…è¨±å­—æ¯ã€æ•¸å­—ã€åº•ç·šã€ç ´æŠ˜è™Ÿã€æ‹¬è™Ÿã€é»è™Ÿï¼Œé•·åº¦é™åˆ¶åœ¨1-200å­—å…ƒ
        # é€™äº›å­—å…ƒå°æ–¼CHART IDã€è¨­å‚™IDã€ç»ç’ƒIDç­‰æ˜¯å®‰å…¨çš„
        return bool(re.match(r'^[A-Za-z0-9_\-\(\)\.]{1,200}$', value))
    
    def _is_safe_stmt(self, stmt: str) -> bool:
        """æª¢æŸ¥ TRX stmt æ˜¯å¦å®‰å…¨ï¼ˆé˜²æ­¢ SQL injectionï¼‰"""
        if not stmt or not isinstance(stmt, str):
            return False
        
        # æª¢æŸ¥é•·åº¦é™åˆ¶
        if len(stmt) > 1000:
            return False
        
        # æ‹’çµ•å±éšªå­—å…ƒå’Œæ¨¡å¼
        dangerous_patterns = [
            r';',           # åˆ†è™Ÿ - å¤šèªå¥åŸ·è¡Œ
            r'--',          # SQL è¨»é‡‹
            r'/\*',         # å¤šè¡Œè¨»é‡‹é–‹å§‹
            r'\*/',         # å¤šè¡Œè¨»é‡‹çµæŸ
            r'\bDROP\b',    # DROP èªå¥
            r'\bINSERT\b',  # INSERT èªå¥
            r'\bUPDATE\b',  # UPDATE èªå¥
            r'\bDELETE\b',  # DELETE èªå¥
            r'\bEXEC\b',    # EXEC èªå¥
            r'\bEXECUTE\b', # EXECUTE èªå¥
            r'\bCREATE\b',  # CREATE èªå¥
            r'\bALTER\b',   # ALTER èªå¥
            r'\bUNION\b',   # UNION - å¯èƒ½ç”¨æ–¼æ•¸æ“šæ´©éœ²
            r'\bXP_\w+',    # æ“´å±•å­˜å„²éç¨‹
        ]
        
        stmt_upper = stmt.upper()
        for pattern in dangerous_patterns:
            if re.search(pattern, stmt_upper, re.IGNORECASE):
                return False
        
        # åªå…è¨±åŸºæœ¬çš„ WHERE æ¢ä»¶èªæ³•
        # å…è¨±ï¼šæ¬„ä½åã€=ã€>ã€<ã€>=ã€<=ã€ANDã€ORã€NOTã€æ‹¬è™Ÿã€å–®å¼•è™Ÿå­—ä¸²ã€æ•¸å­—
        allowed_pattern = r"^[A-Za-z0-9_\.\s=><!'\"%()\,\-ANDORNOTandornot]+$"
        return bool(re.match(allowed_pattern, stmt))
    
    def _sanitize_stmt_for_display(self, stmt: str) -> str:
        """å®‰å…¨åŒ– stmt ç”¨æ–¼é¡¯ç¤ºï¼ˆç§»é™¤æ½›åœ¨å±éšªå…§å®¹ï¼‰"""
        if not stmt:
            return ""
        # ç§»é™¤è¨»é‡‹
        stmt = re.sub(r'--.*?(\n|$)', '', stmt, flags=re.MULTILINE)
        stmt = re.sub(r'/\*.*?\*/', '', stmt, flags=re.DOTALL)
        # é™åˆ¶é•·åº¦
        return stmt[:500] + "..." if len(stmt) > 500 else stmt
    
    def get_name(self) -> str:
        return "spc_query"
    
    def get_description(self) -> str:
        return """åŸ·è¡ŒSPCç³»çµ±è¨ºæ–·ï¼Œæª¢æŸ¥è³‡æ–™æ˜¯å¦é€²å…¥ç®¡åˆ¶åœ–ï¼ˆCHARTï¼‰ã€‚
        é©ç”¨æƒ…æ³ï¼š
        - ç•¶ç”¨æˆ¶æä¾›å» åˆ¥ã€æ™‚é–“ã€ç»ç’ƒIDã€è¨­å‚™IDã€CHART IDç­‰è³‡è¨Šæ™‚
        - æŸ¥è©¢ã€Œç‚ºä»€éº¼SPCæ²’æœ‰é€²CHARTã€æˆ–ã€Œè³‡æ–™æ˜¯å¦æœ‰é€²CHARTã€
        - è¨ºæ–·SPCç³»çµ±å•é¡Œæˆ–è¨­å‚™ç‹€æ…‹
        - æª¢æŸ¥çµ±è¨ˆè£½ç¨‹ç®¡åˆ¶åœ–ç‹€æ…‹
        
        æ³¨æ„ï¼šé€™æ˜¯ä¸»è¦çš„SPCè¨ºæ–·å·¥å…·ï¼Œä¸æ˜¯è©³ç´°è³‡æ–™æŸ¥çœ‹å·¥å…·ã€‚"""
    
    def execute(self, query: str) -> str:
        try:
            # 1. å¾ç”¨æˆ¶æŸ¥è©¢ä¸­æå–é—œéµè³‡è¨Š
            info = self._extract_spc_info(query)
            
            # 2. æª¢æŸ¥æ˜¯å¦æä¾›å¿…è¦çš„äº”å€‹æ¢ä»¶
            missing_conditions = self._check_required_spc_conditions(info)
            
            if missing_conditions:
                return self._request_missing_spc_info(missing_conditions, info)
            
            # 3. å¦‚æœè³‡è¨Šå®Œæ•´ï¼Œé€²è¡Œå¯¦éš›æŸ¥è©¢
            return self._perform_spc_diagnosis(info)
            
        except Exception as e:
            return f"""âš ï¸ SPC è¨ºæ–·éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}

**æ‰‹å‹•æ’æŸ¥å»ºè­°ï¼š**
1. æª¢æŸ¥ä¸Šå ±æ™‚é–“æ ¼å¼æ˜¯å¦æ­£ç¢º
2. ç¢ºèªç»ç’ƒIDæ˜¯å¦å­˜åœ¨æ–¼ç³»çµ±ä¸­
3. é©—è­‰è¨­å‚™IDæ˜¯å¦æ­£å¸¸é‹ä½œ
4. æª¢æŸ¥CHART IDé…ç½®

**è«‹æä¾›ä»¥ä¸‹å®Œæ•´è³‡è¨Šä»¥é€²è¡Œäººå·¥è¨ºæ–·ï¼š**
- å» åˆ¥(TFT6/CF6/LCD6/USL)
- ä¸Šå ±æ™‚é–“ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)
- ç»ç’ƒID
- è¨­å‚™ID  
- CHART ID"""

    def _extract_spc_info(self, query: str) -> Dict[str, Any]:
        """å¾æŸ¥è©¢ä¸­æå– SPC ç›¸é—œè³‡è¨Š"""
        info = {
            "factory": None,
            "timestamp": None,
            "glass_id": None,
            "equipment_id": None,
            "chart_id": None,
            "raw_query": query,
            "extracted_count": 0
        }
        
        # æå–å» åˆ¥
        factory_patterns = [
            r'å» åˆ¥\s*[:ï¼š]\s*(TFT6|CF6|LCD6|USL)',
            r'FACTORY\s*[:ï¼š]\s*(TFT6|CF6|LCD6|USL)',
            r'\b(TFT6|CF6|LCD6|USL)\b',
        ]
        for pattern in factory_patterns:
            factory_match = re.search(pattern, query.upper())
            if factory_match:
                info["factory"] = factory_match.group(1)
                info["extracted_count"] += 1
                break
        
        # æå–æ™‚é–“æ ¼å¼ - æ”¯æ´å¤šç¨®æ ¼å¼
        time_patterns = [
            # æ¨™æº–æ ¼å¼: 2025-09-03 14:30:05
            r'ä¸Šå ±æ™‚é–“\s*[:ï¼š]\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
            r'æ™‚é–“\s*[:ï¼š]\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
            r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
            # æª”æ¡ˆåæ ¼å¼: 2025-09-03-09.40.00
            r'ä¸Šå ±æ™‚é–“\s*[:ï¼š]\s*(\d{4}-\d{2}-\d{2}-\d{2}\.\d{2}\.\d{2})',
            r'æ™‚é–“\s*[:ï¼š]\s*(\d{4}-\d{2}-\d{2}-\d{2}\.\d{2}\.\d{2})',
            r'(\d{4}-\d{2}-\d{2}-\d{2}\.\d{2}\.\d{2})',
            # æ–œç·šæ ¼å¼: 2025/09/03 14:30:05
            r'(\d{4}/\d{2}/\d{2}\s+\d{2}:\d{2}:\d{2})',
        ]
        for pattern in time_patterns:
            time_match = re.search(pattern, query)
            if time_match:
                raw_time = time_match.group(1)
                # æ­£è¦åŒ–æ™‚é–“æ ¼å¼ç‚ºæ¨™æº–æ ¼å¼
                if '-' in raw_time and '.' in raw_time:
                    # è½‰æ› 2025-09-03-09.40.00 -> 2025-09-03 09:40:00
                    parts = raw_time.split('-')
                    if len(parts) == 4:  # YYYY-MM-DD-HH.MM.SS
                        date_part = '-'.join(parts[:3])  # YYYY-MM-DD
                        time_part = parts[3].replace('.', ':')  # HH:MM:SS
                        info["timestamp"] = f"{date_part} {time_part}"
                    else:
                        info["timestamp"] = raw_time
                else:
                    info["timestamp"] = raw_time
                info["extracted_count"] += 1
                break
        
        # æå–ç»ç’ƒID
        glass_patterns = [
            r'ç»ç’ƒID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'GLASS\s*ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'Glass\s*ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'SHT_ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
        ]
        for pattern in glass_patterns:
            glass_match = re.search(pattern, query)
            if glass_match:
                info["glass_id"] = glass_match.group(1)
                info["extracted_count"] += 1
                break
        
        # æå–è¨­å‚™ID
        equipment_patterns = [
            r'è¨­å‚™ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'è¨­å‚™\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'EQUIPMENT\s*ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            r'EQP_ID\s*[:ï¼š]\s*([A-Za-z0-9]+)',
            # æ–°å¢æ›´å¯¬é¬†çš„æ¨¡å¼
            r'è¨­å‚™ID[ï¼š:]\s*([A-Za-z0-9]+)',
            r'è¨­å‚™ID\s+([A-Za-z0-9]+)',
            r'\b([A-Z]{2,6}\d{4,6})\b',  # åŒ¹é…è¨­å‚™IDæ ¼å¼å¦‚ IMRV0100
        ]
        for pattern in equipment_patterns:
            eq_match = re.search(pattern, query)
            if eq_match:
                potential_equipment = eq_match.group(1)
                # ç¢ºä¿ä¸æ˜¯å…¶ä»–ID (é¿å…èª¤åˆ¤ç»ç’ƒIDç­‰)ï¼Œä½†å…è¨±T6é–‹é ­çš„è¨­å‚™
                if len(potential_equipment) >= 6:
                    info["equipment_id"] = potential_equipment
                    info["extracted_count"] += 1
                    break
        
        # æå–CHART ID
        chart_patterns = [
            r'CHART\s*ID\s*[:ï¼š]\s*([A-Za-z0-9_\(\)\-\.]+)',
            r'Chart\s*ID\s*[:ï¼š]\s*([A-Za-z0-9_\(\)\-\.]+)',
            r'ONCHID\s*[:ï¼š]\s*([A-Za-z0-9_\(\)\-\.]+)',
            # æ–°å¢æ›´å¯¬é¬†çš„æ¨¡å¼
            r'CHART\s*ID[ï¼š:]\s*([A-Za-z0-9_\(\)\-\.]+)',
            r'CHART\s+ID\s+([A-Za-z0-9_\(\)\-\.]+)',
            r'\b(SPD[A-Z0-9_\(\)\-\.]+)\b',  # åŒ¹é…CHART IDæ ¼å¼å¦‚ SPDV1400_2353_TOTAL
            r'\b(E\d+[A-Z0-9_\(\)\-\.]*)\b',  # åŒ¹é…E904é–‹é ­çš„CHART IDæ ¼å¼
        ]
        for pattern in chart_patterns:
            chart_match = re.search(pattern, query)
            if chart_match:
                info["chart_id"] = chart_match.group(1)
                info["extracted_count"] += 1
                break
        
        return info

    def _check_required_spc_conditions(self, info: Dict[str, Any]) -> List[str]:
        """æª¢æŸ¥ SPC æŸ¥è©¢å¿…è¦çš„äº”å€‹æ¢ä»¶"""
        missing_conditions = []
        
        if not info.get("factory"):
            missing_conditions.append("å» åˆ¥")
        if not info.get("timestamp"):
            missing_conditions.append("ä¸Šå ±æ™‚é–“")
        if not info.get("glass_id"):
            missing_conditions.append("ç»ç’ƒID")
        if not info.get("equipment_id"):
            missing_conditions.append("è¨­å‚™ID")
        if not info.get("chart_id"):
            missing_conditions.append("CHART ID")
        
        return missing_conditions

    def _request_missing_spc_info(self, missing_conditions: List[str], info: Dict[str, Any]) -> str:
        """è«‹æ±‚ç”¨æˆ¶æä¾›ç¼ºå¤±çš„ SPC è³‡è¨Š"""
        
        # é¡¯ç¤ºå·²æå–åˆ°çš„è³‡è¨Š
        extracted_info = []
        if info.get("factory"):
            extracted_info.append(f"âœ… å» åˆ¥: {info['factory']}")
        if info.get("timestamp"):
            extracted_info.append(f"âœ… ä¸Šå ±æ™‚é–“: {info['timestamp']}")
        if info.get("glass_id"):
            extracted_info.append(f"âœ… ç»ç’ƒID: {info['glass_id']}")
        if info.get("equipment_id"):
            extracted_info.append(f"âœ… è¨­å‚™ID: {info['equipment_id']}")
        if info.get("chart_id"):
            extracted_info.append(f"âœ… CHART ID: {info['chart_id']}")
        
        # é¡¯ç¤ºç¼ºå°‘çš„è³‡è¨Š
        missing_info = []
        for condition in missing_conditions:
            missing_info.append(f"âŒ ç¼ºå°‘: {condition}")
        
        if extracted_info:
            response = f"""ğŸ“‹ **è³‡è¨Šæª¢æŸ¥çµæœï¼š**

**å·²æå–åˆ°çš„è³‡è¨Šï¼š**
{chr(10).join(extracted_info)}

**é‚„éœ€è¦è£œå……ï¼š**
{chr(10).join(missing_info)}

è«‹è£œå……ç¼ºå°‘çš„è³‡è¨Šï¼Œä¾‹å¦‚ï¼š
ã€Œå» åˆ¥:TFT6ï¼Œä¸Šå ±æ™‚é–“:2025-08-28 14:30:05ï¼Œç»ç’ƒID:T65833S0BA01ï¼Œè¨­å‚™ID:TPAB0106ï¼ŒCHART ID:TPAB0106_2F10_67D2_AUWitdh_01ã€"""
        else:
            response = """è¦å¹«æ‚¨æŸ¥è©¢ã€ŒSPCç‚ºä»€éº¼æ²’æœ‰é€²CHARTã€ï¼Œæˆ‘éœ€è¦ä»¥ä¸‹äº”å€‹è³‡è¨Šï¼š

1. å» åˆ¥ï¼ˆä¾‹å¦‚ï¼šTFT6/CF6/LCD6/USLï¼‰
2. ä¸Šå ±æ™‚é–“ï¼ˆä¾‹å¦‚ï¼š2025-08-28 14:30:05ï¼‰
3. ç»ç’ƒ IDï¼ˆä¾‹å¦‚ï¼šT65833S0BA01ï¼‰
4. è¨­å‚™ IDï¼ˆä¾‹å¦‚ï¼šTPAB0106ï¼‰
5. Chart IDï¼ˆä¾‹å¦‚ï¼šTPAB0106_2F10_67D2_AUWitdh_01ï¼‰

**ğŸ“ ç¯„ä¾‹æ ¼å¼ï¼š**
ã€Œå» åˆ¥:USLï¼Œä¸Šå ±æ™‚é–“:2025-09-04 08:34:56ï¼Œç»ç’ƒID:T357M6V1NL21ï¼Œè¨­å‚™ID:CSLI4204 ï¼ŒCHART ID:E904(015T)_3000_CSLI4204_CF_LL_Cor_CP_Xã€"""
        
        return response

    def _perform_spc_diagnosis(self, info: Dict[str, Any]) -> str:
        """åŸ·è¡Œå®Œæ•´çš„ SPC è¨ºæ–·æµç¨‹"""
        result = [f"ğŸ”§ **SPC CHART è¨ºæ–·é–‹å§‹**"]
        result.append(f"**æŸ¥è©¢è³‡è¨Šï¼š** å» åˆ¥:{info['factory']}, æ™‚é–“:{info['timestamp']}, ç»ç’ƒID:{info['glass_id']}, è¨­å‚™ID:{info['equipment_id']}, CHART ID:{info['chart_id']}")
        result.append("")
        
        try:
            # æ­¥é©Ÿ 4-8: æŸ¥è©¢ TRX LOG
            trx_results = self._query_trx_log(info)
            result.append("ğŸ“Š **TRX LOG æŸ¥è©¢çµæœï¼š**")
            
            if trx_results["success"]:
                result.append("âœ… TRX LOG æŸ¥è©¢æˆåŠŸ")
                if 't_stamp' in trx_results:
                    result.append(f"ğŸ• äº¤æ˜“æ™‚é–“: {trx_results['t_stamp']}")
                
                # ç›´æ¥é¡¯ç¤ºTRX LOGè©³ç´°è³‡æ–™
                if 'detail' in trx_results and trx_results['detail']:
                    detail = trx_results['detail']
                    if 'evntlgDetail' in detail:
                        event_detail = detail['evntlgDetail']
                        result.append(f"ğŸ“‹ è¨­å‚™ID: {event_detail.get('eqptId', 'N/A')}, ç»ç’ƒID: {event_detail.get('shtId', 'N/A')}")
                        result.append(f"ğŸ“‹ éŒ¯èª¤ç¢¼: {event_detail.get('errcode', 'N/A')}, è™•ç†æ™‚é–“: {event_detail.get('procTime', 'N/A')}ms")
                    else:
                        result.append(f"ğŸ“‹ è¨­å‚™ID: {detail.get('eqptId', 'N/A')}, ç»ç’ƒID: {detail.get('shtId', 'N/A')}")
                        result.append(f"ğŸ“‹ éŒ¯èª¤ç¢¼: {detail.get('errcode', 'N/A')}, è™•ç†æ™‚é–“: {detail.get('procTime', 'N/A')}ms")
                    
                    result.append("")
                    # ç›´æ¥é¡¯ç¤ºè©³ç´°è³‡æ–™
                    trx_details = self._format_trx_details(trx_results)
                    result.extend(trx_details)
            else:
                result.append("âŒ TRX LOG æŸ¥è©¢å¤±æ•—")
                # åªé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼Œä¸é¡¯ç¤ºè©³ç´°éç¨‹
                error_messages = [msg for msg in trx_results["messages"] if "âŒ" in msg]
                result.extend(error_messages[:3])  # æœ€å¤šé¡¯ç¤º3å€‹éŒ¯èª¤è¨Šæ¯
            
            result.append("")
            
            # å³ä½¿TRX LOGæŸ¥è©¢å¤±æ•—ï¼Œä¹Ÿè¦ç¹¼çºŒé€²è¡ŒSPCè³‡æ–™åº«æŸ¥è©¢
            if not trx_results["success"]:
                result.append("âš ï¸ TRX LOG æŸ¥è©¢å¤±æ•—ï¼Œå°‡åƒ…é€²è¡ŒSPCè³‡æ–™åº«æŸ¥è©¢")
                result.append("")
            
            # æ­¥é©Ÿ 9: æŸ¥è©¢ SPC DB ç¢ºèªæ˜¯å¦æœ‰é€² CHART
            spc_data = self._query_spc_db(info)
            result.append("ğŸ—„ï¸ **SPC è³‡æ–™åº«æŸ¥è©¢çµæœï¼š**")
            result.append(f"ğŸ“‹ åŸ·è¡ŒSQL: `{spc_data.get('sql', 'N/A')}`")
            result.append("")
            
            if spc_data["found"]:
                result.append("âœ… **è©²ç­†è³‡æ–™å·²é€²å…¥ CHART**")
                result.append(f"æ‰¾åˆ° {len(spc_data['data'])} ç­†ç›¸é—œè³‡æ–™")
                
                # å„²å­˜è©³ç´°è³‡æ–™åˆ°æŸ¥çœ‹å·¥å…·
                if self.detail_viewer and spc_data['data']:
                    self.detail_viewer.store_data(spc_data['data'], trx_results)
                
                # é¡¯ç¤ºæ‘˜è¦è³‡è¨Š
                if spc_data['data']:
                    result.append("")
                    result.append("ğŸ“Š **è³‡æ–™æ‘˜è¦ï¼š**")
                    for i, row in enumerate(spc_data['data']):
                        if isinstance(row, dict):
                            result.append(f"**ç¬¬{i+1}ç­†ï¼š** ç»ç’ƒID: {row.get('SHT_ID', 'N/A')}, è¨­å‚™ID: {row.get('EQPT_ID', 'N/A')}, CHART ID: {row.get('ONCHID', 'N/A')}")
                            result.append(f"         æ™‚é–“: {row.get('T_STAMP', 'N/A')}, ç”¢å“: {row.get('PRODUCT_ID', 'N/A')}")
                    
                    # ç›´æ¥é¡¯ç¤ºSPCè³‡æ–™åº«è©³ç´°è³‡æ–™
                    result.append("")
                    spc_details = self._format_spc_details(spc_data['data'])
                    result.extend(spc_details)
                
                # æ·»åŠ è¨ºæ–·ç¸½çµ
                result.append("")
                result.append("---")
                result.append("ğŸ¯ **è¨ºæ–·ç¸½çµ**  ")
                result.append("âœ… **çµè«–ï¼šè©²ç­†è³‡æ–™å·²æˆåŠŸé€²å…¥ SPC CHART**  ")
                result.append("")
                result.append("ğŸ“‹ **é—œéµè³‡è¨Šï¼š**  ")
                result.append(f"  â€¢ ç»ç’ƒID: {info['glass_id']}  ")
                result.append(f"  â€¢ è¨­å‚™ID: {info['equipment_id']}  ")
                result.append(f"  â€¢ CHART ID: {info['chart_id']}  ")
                result.append(f"  â€¢ é€²å…¥æ™‚é–“: {spc_data['data'][0].get('T_STAMP', 'N/A') if spc_data['data'] else 'N/A'}  ")
                result.append("---")
                
                return "\n".join(result)
            else:
                result.append("âŒ **è©²ç­†è³‡æ–™å°šæœªé€²å…¥ CHARTï¼Œç¹¼çºŒåˆ†æåŸå› ...**")
                result.append(f"ğŸ” æŸ¥è©¢SQL: `{spc_data.get('sql', 'N/A')}`")
                if 'error' in spc_data:
                    result.append(f"âŒ éŒ¯èª¤: {spc_data['error']}")
                result.append("")
            
            # æ­¥é©Ÿ 11: æŸ¥è©¢ CHART è¨­å®š
            chart_config = self._query_chart_config(info)
            result.append("âš™ï¸ **CHART è¨­å®šæŸ¥è©¢çµæœï¼š**")
            if chart_config["found"]:
                result.append(f"âœ… æ‰¾åˆ° CHART è¨­å®šï¼Œå…± {len(chart_config['data'])} ç­†")
                # é¡¯ç¤º CHART è¨­å®šè©³æƒ…
                if chart_config['data']:
                    chart_item = chart_config['data'][0]
                    result.append(f"**CHARTè¨­å®šè©³æƒ…ï¼š**")
                    result.append(f"  - CHART ID: {chart_item.get('ONCHID', 'N/A')}")
                    result.append(f"  - ç‹€æ…‹: {chart_item.get('STATUS', 'N/A')}")
                    result.append(f"  - è¨­å‚™ID: {chart_item.get('EQP_ID', 'N/A')}")
            else:
                result.append("âŒ æœªæ‰¾åˆ°å°æ‡‰çš„ CHART è¨­å®š")
                result.append("**å¯èƒ½åŸå› ï¼šCHART ID ä¸å­˜åœ¨æˆ–é…ç½®éŒ¯èª¤**")
            result.append("")
            
            # æ­¥é©Ÿ 12-18: åˆ†ææ¢ä»¶æ¯”å°ï¼ˆåƒ…åœ¨TRX LOGæˆåŠŸæ™‚é€²è¡Œï¼‰
            if trx_results["success"]:
                analysis = self._analyze_chart_conditions(info, trx_results, chart_config)
                result.append("ğŸ” **æ¢ä»¶æ¯”å°åˆ†æï¼š**")
                result.extend(analysis)
            else:
                result.append("ğŸ” **æ¢ä»¶æ¯”å°åˆ†æï¼š**")
                result.append("   âš ï¸ ç”±æ–¼TRX LOGæŸ¥è©¢å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œè©³ç´°æ¢ä»¶æ¯”å°")
            
            # æ·»åŠ è¨ºæ–·ç¸½çµï¼ˆæœªé€²å…¥CHARTçš„æƒ…æ³ï¼‰
            result.append("")
            result.append("---")
            result.append("ğŸ¯ **è¨ºæ–·ç¸½çµ**  ")
            result.append("âŒ **çµè«–ï¼šè©²ç­†è³‡æ–™å°šæœªé€²å…¥ SPC CHART**  ")
            result.append("")
            result.append("ğŸ“‹ **é—œéµè³‡è¨Šï¼š**  ")
            result.append(f"  â€¢ ç»ç’ƒID: {info['glass_id']}  ")
            result.append(f"  â€¢ è¨­å‚™ID: {info['equipment_id']}  ")
            result.append(f"  â€¢ CHART ID: {info['chart_id']}  ")
            result.append(f"  â€¢ TRX LOG ç‹€æ…‹: {'âœ… æˆåŠŸ' if trx_results.get('success') else 'âŒ å¤±æ•—'}  ")
            result.append(f"  â€¢ CHART è¨­å®š: {'âœ… å­˜åœ¨' if chart_config.get('found') else 'âŒ ä¸å­˜åœ¨'}  ")
            result.append("")
            result.append("ğŸ’¡ **å»ºè­°æ’æŸ¥æ–¹å‘ï¼š**  ")
            if not chart_config.get("found"):
                result.append("  1. æª¢æŸ¥ CHART ID æ˜¯å¦æ­£ç¢ºé…ç½®  ")
                result.append("  2. ç¢ºèª CHART è¨­å®šæ˜¯å¦å•Ÿç”¨  ")
            else:
                result.append("  1. æª¢æŸ¥è¨­å‚™IDèˆ‡CHARTè¨­å®šæ˜¯å¦åŒ¹é…  ")
                result.append("  2. ç¢ºèªæ™‚é–“ç¯„åœæ˜¯å¦æ­£ç¢º  ")
                result.append("  3. æª¢æŸ¥è³‡æ–™æ ¼å¼æ˜¯å¦ç¬¦åˆCHARTè¦æ±‚  ")
            if not trx_results["success"]:
                result.append("  4. æª¢æŸ¥TRX LOGæŸ¥è©¢åƒæ•¸ï¼ˆæ™‚é–“ã€è¨­å‚™IDã€ç»ç’ƒIDï¼‰  ")
            result.append("  5. è¯ç¹«SPCå·¥ç¨‹å¸«é€²è¡Œé€²ä¸€æ­¥è¨ºæ–·  ")
            result.append("---")
            
            return "\n".join(result)
            
        except Exception as e:
            result.append(f"âŒ è¨ºæ–·éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return "\n".join(result)

    def _query_trx_log(self, info: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥è©¢ TRX LOG (æ­¥é©Ÿ 4-8)"""
        factory = info["factory"]
        timestamp = info["timestamp"]
        factory_config = self.factory_map[factory]
        
        # è¨ˆç®—æ™‚é–“ç¯„åœ (å‰å¾ŒåŠå°æ™‚)
        try:
            dt = datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
            from_dt = (dt - timedelta(minutes=30)).strftime("%Y/%m/%d %H:%M:%S")
            to_dt = (dt + timedelta(minutes=30)).strftime("%Y/%m/%d %H:%M:%S")
        except:
            return {"success": False, "messages": ["âŒ æ™‚é–“æ ¼å¼éŒ¯èª¤"]}
        
        messages = []
        
        try:
            # æ­¥é©Ÿ 4: åˆå§‹æŸ¥è©¢ (pageSize=2)
            url1 = f"{self.base_url}/MesLogApi/{factory}/trx-log"
            params1 = {
                "fromDT": from_dt,
                "toDT": to_dt,
                "svrModules": factory_config["svr"],
                "shtId": info["glass_id"],
                "eqptId": info["equipment_id"],
                "lastTStamp": "",
                "pageSize": 2
            }
            
            messages.append(f"ğŸ” æ­¥é©Ÿ4: æŸ¥è©¢æ™‚é–“ç¯„åœå…§çš„ TRX LOG...")
            messages.append(f"   URL: {url1}")
            messages.append(f"   æ™‚é–“ç¯„åœ: {from_dt} ~ {to_dt}")
            
            # æ­¥é©Ÿ4: å¯¦éš›ç™¼é€ HTTP è«‹æ±‚
            response1 = requests.get(url1, params=params1, timeout=30)
            if response1.status_code != 200:
                messages.append(f"âŒ APIè«‹æ±‚å¤±æ•—: HTTP {response1.status_code}")
                return {"success": False, "messages": messages}
            
            trx_data = response1.json()
            
            # è™•ç†ä¸åŒçš„ API å›æ‡‰æ ¼å¼
            if isinstance(trx_data, list):
                # å¦‚æœ API ç›´æ¥è¿”å› list
                data_list = trx_data
            elif isinstance(trx_data, dict) and "data" in trx_data:
                # å¦‚æœ API è¿”å›åŒ…å« data æ¬„ä½çš„ dict
                data_list = trx_data.get("data", [])
            else:
                # å…¶ä»–æ ¼å¼ï¼Œå˜—è©¦ç•¶ä½œ list è™•ç†
                data_list = []
                messages.append(f"âš ï¸ æœªé æœŸçš„ API å›æ‡‰æ ¼å¼: {type(trx_data)}")
            
            count = len(data_list)
            
            if count == 1:
                messages.append("âœ… æ­¥é©Ÿ5: æ™‚é–“ç¯„åœæº–ç¢ºï¼Œæ‰¾åˆ°1ç­†è¨˜éŒ„")
                t_stamp = data_list[0]["tStamp"]
            elif count > 1:
                messages.append("âš ï¸ æ­¥é©Ÿ5: æ™‚é–“ç¯„åœéå¤§ï¼Œè«‹æä¾›æ›´ç²¾ç¢ºçš„æ™‚é–“")
                return {"success": False, "messages": messages}
            else:
                messages.append("âŒ æ­¥é©Ÿ5: è©²æ™‚é–“ç¯„åœå…§ç„¡è¨˜éŒ„")
                return {"success": False, "messages": messages}
            
            # æ­¥é©Ÿ 6: ç²¾ç¢ºæŸ¥è©¢ (pageSize=1)
            params2 = params1.copy()
            params2["pageSize"] = 1
            messages.append(f"ğŸ” æ­¥é©Ÿ6: ç²¾ç¢ºæŸ¥è©¢...")
            messages.append(f"   URL: {url1}")
            messages.append(f"   åƒæ•¸: pageSize=1, fromDT={from_dt}, toDT={to_dt}")
            
            response2 = requests.get(url1, params=params2, timeout=30)
            if response2.status_code != 200:
                messages.append(f"âŒ æ­¥é©Ÿ6 APIè«‹æ±‚å¤±æ•—: HTTP {response2.status_code}")
                return {"success": False, "messages": messages}
            
            # è™•ç†æ­¥é©Ÿ6çš„å›æ‡‰
            trx_data2 = response2.json()
            messages.append(f"âœ… æ­¥é©Ÿ6 æŸ¥è©¢æˆåŠŸï¼Œå›æ‡‰è³‡æ–™: {json.dumps(trx_data2, ensure_ascii=False, indent=2)}")
            
            # æ­¥é©Ÿ 7: æŸ¥è©¢è©³ç´°è³‡æ–™
            url3 = f"{self.base_url}/MesLogApi/{factory}/trx-log/{factory_config['svr']}/{t_stamp}"
            params3 = {"ignoreBody": "false"}
            messages.append(f"ğŸ” æ­¥é©Ÿ7: æŸ¥è©¢è©³ç´°TRXè³‡æ–™...")
            messages.append(f"   URL: {url3}")
            
            response3 = requests.get(url3, params=params3, timeout=30)
            if response3.status_code != 200:
                messages.append(f"âŒ æ­¥é©Ÿ7 APIè«‹æ±‚å¤±æ•—: HTTP {response3.status_code}")
                return {"success": False, "messages": messages}
            
            detail_data = response3.json()
            
            messages.append("âœ… æ­¥é©Ÿ8: TRX LOG æŸ¥è©¢å®Œæˆ")
            messages.append("")
            messages.append("ğŸ“‹ **TRX LOG è©³ç´°è³‡æ–™ï¼š**")
            
            # é¡¯ç¤ºåˆå§‹æŸ¥è©¢çµæœ (æ­¥é©Ÿ4)
            messages.append("**ğŸ“Š Tab 1: åˆå§‹æŸ¥è©¢çµæœ (æ­¥é©Ÿ4 - pageSize=2)**")
            if data_list:
                for i, item in enumerate(data_list):
                    messages.append(f"   ç¬¬{i+1}ç­†: {json.dumps(item, ensure_ascii=False, indent=2)}")
            else:
                messages.append("   ç„¡è³‡æ–™")
            
            messages.append("")
            messages.append("**ğŸ“Š Tab 2: ç²¾ç¢ºæŸ¥è©¢çµæœ (æ­¥é©Ÿ6 - pageSize=1)**")
            if 'trx_data2' in locals():
                if isinstance(trx_data2, list):
                    for i, item in enumerate(trx_data2):
                        messages.append(f"   ç¬¬{i+1}ç­†: {json.dumps(item, ensure_ascii=False, indent=2)}")
                elif isinstance(trx_data2, dict) and "data" in trx_data2:
                    data_list2 = trx_data2.get("data", [])
                    for i, item in enumerate(data_list2):
                        messages.append(f"   ç¬¬{i+1}ç­†: {json.dumps(item, ensure_ascii=False, indent=2)}")
                else:
                    messages.append(f"   åŸå§‹è³‡æ–™: {json.dumps(trx_data2, ensure_ascii=False, indent=2)}")
            else:
                messages.append("   ç„¡è³‡æ–™")
            
            messages.append("")
            messages.append("**ğŸ“Š Tab 3: è©³ç´°TRXè³‡æ–™ (æ­¥é©Ÿ7)**")
            if detail_data:
                # æ ¼å¼åŒ–é¡¯ç¤ºè©³ç´°è³‡æ–™
                if isinstance(detail_data, dict):
                    for key, value in detail_data.items():
                        if isinstance(value, (dict, list)):
                            messages.append(f"   {key}: {json.dumps(value, ensure_ascii=False, indent=2)}")
                        else:
                            messages.append(f"   {key}: {value}")
                else:
                    messages.append(f"   è³‡æ–™: {json.dumps(detail_data, ensure_ascii=False, indent=2)}")
            else:
                messages.append("   ç„¡è©³ç´°è³‡æ–™")
            
            return {
                "success": True,
                "messages": messages,
                "t_stamp": t_stamp,
                "detail": detail_data
            }
            
        except requests.RequestException as e:
            messages.append(f"âŒ ç¶²è·¯è«‹æ±‚éŒ¯èª¤: {str(e)}")
            return {"success": False, "messages": messages}
        except Exception as e:
            messages.append(f"âŒ TRX LOG æŸ¥è©¢éŒ¯èª¤: {str(e)}")
            return {"success": False, "messages": messages}

    def _query_spc_db(self, info: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥è©¢ SPC DB (æ­¥é©Ÿ 9)"""
        factory = info["factory"]
        glass_id = info["glass_id"]
        factory_config = self.factory_map[factory]
        
        # å®‰å…¨æª¢æŸ¥ï¼šé©—è­‰ glass_id æ ¼å¼
        if not self._is_safe_identifier(glass_id):
            return {
                "found": False,
                "data": [],
                "error": f"glass_id æ ¼å¼ä¸å®‰å…¨ï¼Œå·²æ‹’çµ•æŸ¥è©¢: {glass_id}",
                "sql": None
            }
        
        # æ§‹å»ºæŸ¥è©¢ SQL - ä½¿ç”¨å®‰å…¨çš„å­—ä¸²é€ƒé€¸ï¼Œä¸¦åŠ ä¸Šè¨­å‚™IDå’ŒCHART IDæ¢ä»¶
        safe_glass_id = glass_id.replace("'", "''")  # SQL æ¨™æº–çš„å–®å¼•è™Ÿé€ƒé€¸
        safe_equipment_id = info["equipment_id"].replace("'", "''")
        safe_chart_id = info["chart_id"].replace("'", "''")
        
        sql = f"""SELECT * FROM {factory_config['data_schema']}.{factory_config['glsinfo_table']} a 
        inner join {factory_config['data_schema']}.{factory_config['para_table']} b
            on a.SEQ = b.SEQ
        WHERE a.SHT_ID = '{safe_glass_id}' AND a.eqpt_id = '{safe_equipment_id}' AND b.ONCHID = '{safe_chart_id}'"""
        
        try:
            # ä½¿ç”¨è¬ç”¨æŸ¥è©¢ API
            result = execute_query(sql, "SPC", factory, limit=10)
            
            if result['success']:
                return {
                    "found": result['row_count'] > 0,
                    "data": result['data'],
                    "sql": sql,
                    "row_count": result['row_count']
                }
            else:
                return {
                    "found": False,
                    "data": [],
                    "error": result.get('message', 'æŸ¥è©¢å¤±æ•—'),
                    "sql": sql
                }
            
        except Exception as e:
            return {
                "found": False,
                "data": [],
                "error": str(e),
                "sql": sql
            }

    def _query_chart_config(self, info: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥è©¢ CHART è¨­å®š (æ­¥é©Ÿ 11)"""
        factory = info["factory"]
        chart_id = info["chart_id"]
        factory_config = self.factory_map[factory]
        
        # å®‰å…¨æª¢æŸ¥ï¼šé©—è­‰ chart_id æ ¼å¼
        if not self._is_safe_identifier(chart_id):
            return {
                "found": False,
                "data": [],
                "error": f"chart_id æ ¼å¼ä¸å®‰å…¨ï¼Œå·²æ‹’çµ•æŸ¥è©¢: {chart_id}",
                "sql": None
            }
        
        # æ§‹å»ºæŸ¥è©¢ SQL - ä½¿ç”¨å®‰å…¨çš„å­—ä¸²é€ƒé€¸ï¼Œä¸¦ä½¿ç”¨æ­£ç¢ºçš„ MES schema
        safe_chart_id = chart_id.replace("'", "''")  # SQL æ¨™æº–çš„å–®å¼•è™Ÿé€ƒé€¸
        # ä½¿ç”¨ MES schema è€Œä¸æ˜¯ data_schema
        mes_schema = factory_config.get('mes_schema', factory_config['data_schema'])
        sql = f"SELECT * FROM {mes_schema}.{factory_config['sql_table']} WHERE ONCHID = '{safe_chart_id}'"
        
        try:
            # ä½¿ç”¨è¬ç”¨æŸ¥è©¢ API
            result = execute_query(sql, "MES", factory, limit=10)
            
            if result['success']:
                return {
                    "found": result['row_count'] > 0,
                    "data": result['data'],
                    "sql": sql,
                    "row_count": result['row_count']
                }
            else:
                return {
                    "found": False,
                    "data": [],
                    "error": result.get('message', 'æŸ¥è©¢å¤±æ•—'),
                    "sql": sql
                }
            
        except Exception as e:
            return {
                "found": False,
                "data": [],
                "error": str(e),
                "sql": sql
            }

    def _analyze_chart_conditions(self, info: Dict[str, Any], trx_results: Dict[str, Any], chart_config: Dict[str, Any]) -> List[str]:
        """åˆ†æ CHART æ¢ä»¶æ¯”å° (æ­¥é©Ÿ 12-18)"""
        analysis = []
        factory = info["factory"]
        factory_config = self.factory_map[factory]
        
        # å„²å­˜SPCè³‡æ–™ç”¨æ–¼å¾ŒçºŒæ­¥é©Ÿ
        spc_data = None
        
        try:
            # æ­¥é©Ÿ 12: æ ¹æ“š TRX LOG åˆ†æ Chart_Condition
            analysis.append("ğŸ“ **æ­¥é©Ÿ12: åˆ†æTRX LOGä¸­çš„Chart_Conditionå­—ä¸²**")
            
            # å¾ TRX LOG ä¸­æå– Chart_Condition
            chart_condition = self._extract_chart_condition(trx_results)
            
            if chart_condition:
                analysis.append(f"   å¾TRX LOGæå–çš„Chart_Condition: {chart_condition}")
                
                # å®‰å…¨æª¢æŸ¥ - æœ€é‡è¦çš„é˜²è­·
                if not self._is_safe_stmt(chart_condition):
                    analysis.append("   âŒ **å®‰å…¨è­¦å‘Š**: TRX LOG ä¸­çš„ Chart_Condition åŒ…å«ä¸å®‰å…¨å…§å®¹ï¼Œå·²æ‹’çµ•åŸ·è¡Œä»¥é˜²æ­¢ SQL injection")
                    analysis.append(f"   åŸå§‹ Chart_Condition: {self._sanitize_stmt_for_display(chart_condition)}")
                    analysis.append("   ğŸ’¡ å»ºè­°ï¼šè«‹æª¢æŸ¥ TRX LOG æ•¸æ“šä¾†æºæˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡")
                    return analysis
                
                # é€²ä¸€æ­¥é©—è­‰ï¼šç¢ºä¿ chart_condition åªåŒ…å«å®‰å…¨çš„ WHERE æ¢ä»¶
                clean_condition = chart_condition.strip()
                if not clean_condition:
                    analysis.append("   âŒ TRX LOG ä¸­çš„ Chart_Condition ç‚ºç©ºï¼Œç„¡æ³•åŸ·è¡Œæ¢ä»¶æŸ¥è©¢")
                    return analysis
                
                # æ§‹å»ºå®Œæ•´ SQLï¼Œä½†ä½¿ç”¨é¡å¤–çš„å®‰å…¨é€ƒé€¸ï¼Œä¸¦ä½¿ç”¨æ­£ç¢ºçš„ MES schema
                # æ³¨æ„ï¼šChart_Condition ä¸­çš„å–®å¼•è™Ÿå·²ç¶“æ˜¯æ­£ç¢ºæ ¼å¼ï¼Œä¸éœ€è¦å†æ¬¡é€ƒé€¸
                mes_schema = factory_config.get('mes_schema', factory_config['data_schema'])
                sql_with_conditions = f"SELECT * FROM {mes_schema}.{factory_config['sql_table']} WHERE {clean_condition}"
                analysis.append(f"   åŸ·è¡ŒæŸ¥è©¢: {sql_with_conditions}")
                
                try:
                    # ä½¿ç”¨è¬ç”¨æŸ¥è©¢ API æŸ¥è©¢ç¬¦åˆæ¢ä»¶çš„è³‡æ–™ï¼Œä¸é™åˆ¶ç­†æ•¸
                    matching_result = execute_query(sql_with_conditions, "MES", factory, limit=None)
                    
                    if matching_result['success']:
                        matching_data = matching_result['data']
                        analysis.append(f"   âœ… æŸ¥è©¢æˆåŠŸï¼Œæ‰¾åˆ° {matching_result['row_count']} ç­†ç¬¦åˆæ¢ä»¶çš„è³‡æ–™")
                    else:
                        matching_data = []
                        analysis.append(f"   âŒ æŸ¥è©¢å¤±æ•—: {matching_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}")
                        
                except Exception as e:
                    matching_data = []
                    analysis.append(f"   âŒ æŸ¥è©¢éŒ¯èª¤: {str(e)}")
                
                # æ­¥é©Ÿ 13: æ¯”å°æ˜¯å¦åœ¨ CHART ä¸­
                analysis.append("")
                analysis.append("ğŸ“ **æ­¥é©Ÿ13: æ¯”å°è³‡æ–™æ˜¯å¦åœ¨CHARTä¸­**")
                
                chart_data = chart_config.get("data", [])
                if matching_data:
                    # æª¢æŸ¥æ˜¯å¦èˆ‡ CHART è¨­å®šåŒ¹é…
                    in_chart = any(item.get("ONCHID") == info["chart_id"] for item in matching_data)
                    if in_chart:
                        analysis.append("   âœ… è³‡æ–™æ¢ä»¶ç¬¦åˆï¼Œä½†ä»æœªé€²CHARTï¼Œå¯èƒ½æ˜¯å…¶ä»–å•é¡Œ")
                    else:
                        analysis.append("   âŒ è³‡æ–™ä¸åœ¨æŒ‡å®šçš„CHARTä¸­ï¼Œæ¢ä»¶ä¸ç¬¦")
                else:
                    analysis.append("   âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆTRXæ¢ä»¶çš„è³‡æ–™")
                
                # æ­¥é©Ÿ 14-15: æ¬„ä½æ¯”å°åˆ†æ
                analysis.append("")
                analysis.append("ğŸ“ **æ­¥é©Ÿ14-15: æ¬„ä½æ¢ä»¶æ¯”å°åˆ†æ**")
                
                differences = self._compare_conditions(info, chart_condition, chart_data)
                if differences:
                    analysis.append("   âŒ **ç™¼ç¾ä»¥ä¸‹ä¸ç›¸ç¬¦ä¹‹è™•ï¼š**")
                    for diff in differences:
                        analysis.append(f"     â€¢ {diff}")
                else:
                    analysis.append("   âœ… æ¬„ä½æ¢ä»¶æ¯”å°æ­£å¸¸")
                
                # æ­¥é©Ÿ 16-18: DATA_GROUP æ¯”å°åˆ†æ
                analysis.append("")
                analysis.append("ğŸ“ **æ­¥é©Ÿ16-18: DATA_GROUP æ¯”å°åˆ†æ**")
                
                # ç²å–ç¬¬9æ­¥çš„SPCè³‡æ–™
                spc_data = self._query_spc_db(info)
                
                data_group_analysis = self._analyze_data_group(info, trx_results, chart_condition, spc_data, factory_config)
                analysis.extend(data_group_analysis)
                
                # æœ€çµ‚ç¸½çµ
                analysis.append("")
                analysis.append("ï¿½ **æ­¥é©Ÿ18: ç¸½çµåˆ†æçµæœ**")
                
                all_issues = []
                if differences:
                    all_issues.extend([f"æ¢ä»¶æ¯”å°å•é¡Œ: {diff}" for diff in differences])
                
                # æª¢æŸ¥DATA_GROUPç›¸é—œå•é¡Œ
                data_group_issues = [line for line in data_group_analysis if "âŒ" in line or "ç¼ºå°‘" in line]
                if data_group_issues:
                    all_issues.extend(data_group_issues)
                
                if all_issues:
                    analysis.append("   âŒ **ç™¼ç¾çš„å•é¡Œç¸½çµï¼š**")
                    for issue in all_issues:
                        analysis.append(f"     â€¢ {issue}")
                    analysis.append("")
                    analysis.append("   ï¿½ğŸ’¡ **å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š**")
                    analysis.append("     â€¢ æª¢æŸ¥è¨­å‚™IDè¨­å®šæ˜¯å¦æ­£ç¢º")
                    analysis.append("     â€¢ ç¢ºèªCHARTæ¢ä»¶é…ç½®")
                    analysis.append("     â€¢ æª¢æŸ¥DATA_GROUPè¨­å®šå’Œä¸Šå ±")
                    analysis.append("     â€¢ è¯ç¹«SPCå·¥ç¨‹å¸«æª¢æŸ¥è¨­å®š")
                else:
                    analysis.append("   âœ… æ‰€æœ‰æ¢ä»¶æ¯”å°æ­£å¸¸")
                    analysis.append("   ğŸ’¡ **å…¶ä»–å¯èƒ½åŸå› ï¼š**")
                    analysis.append("     â€¢ è³‡æ–™æ™‚é–“æˆ³å•é¡Œ")
                    analysis.append("     â€¢ ç³»çµ±è™•ç†å»¶é²")
                    analysis.append("     â€¢ è³‡æ–™æ ¼å¼å•é¡Œ")
                
            else:
                analysis.append("   âŒ ç„¡æ³•å¾TRX LOGä¸­æå–Chart_Condition")
                
                # å³ä½¿æ²’æœ‰Chart_Conditionï¼Œä¹ŸåŸ·è¡Œæ­¥é©Ÿ16-17çš„åŸºæœ¬æª¢æŸ¥
                analysis.append("")
                analysis.append("ğŸ“ **æ­¥é©Ÿ16-17: åŸºæœ¬DATA_GROUPæª¢æŸ¥ï¼ˆç„¡Chart_Conditionï¼‰**")
                
                # ç²å–ç¬¬9æ­¥çš„SPCè³‡æ–™
                spc_data = self._query_spc_db(info)
                
                # åŸ·è¡ŒåŸºæœ¬çš„DATA_GROUPæª¢æŸ¥
                basic_data_group_analysis = self._analyze_data_group_basic(info, trx_results, spc_data)
                analysis.extend(basic_data_group_analysis)
                
                # æ­¥é©Ÿ18: ç¸½çµ
                analysis.append("")
                analysis.append("ğŸ“ **æ­¥é©Ÿ18: ç¸½çµåˆ†æçµæœ**")
                analysis.append("   âŒ **ä¸»è¦å•é¡Œï¼šç„¡æ³•æå–Chart_Conditionï¼Œç„¡æ³•é€²è¡Œå®Œæ•´åˆ†æ**")
                analysis.append("   ğŸ’¡ **å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š**")
                analysis.append("     â€¢ æª¢æŸ¥TRX LOGæ ¼å¼æ˜¯å¦æ­£ç¢º")
                analysis.append("     â€¢ ç¢ºèªChart_Conditionæ¬„ä½å­˜åœ¨")
                analysis.append("     â€¢ è¯ç¹«ç³»çµ±ç®¡ç†å“¡æª¢æŸ¥TRX LOGçµæ§‹")
                
        except Exception as e:
            analysis.append(f"   âŒ æ¢ä»¶åˆ†æéŒ¯èª¤: {str(e)}")
        
        return analysis

    def _extract_chart_condition(self, trx_results: Dict[str, Any]) -> str:
        """å¾ TRX LOG ä¸­æå– Chart_Condition å­—ä¸²"""
        try:
            detail = trx_results.get("detail", {})
            
            # æŸ¥æ‰¾åŒ…å« Chart_Condition çš„å…§å®¹
            # å¯èƒ½åœ¨ä¸åŒçš„æ¬„ä½ä¸­
            content_sources = [
                detail.get('inputTrx', ''),
                detail.get('outputTrx', ''),
                detail.get('reqBody', ''),
                detail.get('rspBody', ''),
                detail.get('stmt', ''),
                str(detail.get('evntlgDetail', {}))
            ]
            
            for content in content_sources:
                if not content:
                    continue
                    
                # æŸ¥æ‰¾ Chart_Condition[...] æ ¼å¼
                chart_condition_match = re.search(r'Chart_Condition\[\s*(.*?)\s*\](?:\[\d+\])?', content, re.DOTALL)
                if chart_condition_match:
                    condition = chart_condition_match.group(1).strip()
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ¨™è¨˜ï¼ˆå¦‚ ], lRc=1134081ï¼‰
                    condition = re.sub(r'\s*,\s*lRc=\d+\s*$', '', condition)
                    return condition
            
            return ""
            
        except Exception as e:
            return ""

    def _compare_conditions(self, info: Dict[str, Any], chart_conditions: str, chart_data: List[Dict]) -> List[str]:
        """æ¯”å°æ¢ä»¶å·®ç•°"""
        differences = []
        
        try:
            # å¾ Chart_Condition ä¸­æå–è³‡è¨Š
            trx_eqp_match = re.search(r"EQPT_ID\s*=\s*'([^']+)'", chart_conditions)
            trx_glass_match = re.search(r"GLASS_ID\s*=\s*'([^']+)'", chart_conditions)
            
            if chart_data:
                chart_item = chart_data[0]  # å–ç¬¬ä¸€ç­† CHART è¨­å®š
                
                # æ¯”å°è¨­å‚™ID
                if trx_eqp_match:
                    trx_eqp = trx_eqp_match.group(1)
                    chart_eqp = chart_item.get("EQP_ID", "")
                    if trx_eqp != chart_eqp:
                        differences.append(f"è¨­å‚™IDä¸ç¬¦: Chart_Condition='{trx_eqp}' vs CHART='{chart_eqp}'")
                
                # æ¯”å°ç»ç’ƒID
                if trx_glass_match:
                    trx_glass = trx_glass_match.group(1)
                    info_glass = info.get("glass_id", "")
                    if trx_glass != info_glass:
                        differences.append(f"ç»ç’ƒIDä¸ç¬¦: Chart_Condition='{trx_glass}' vs è¼¸å…¥='{info_glass}'")
                
                # æª¢æŸ¥ CHART ç‹€æ…‹
                chart_status = chart_item.get("STATUS", "")
                if chart_status != "A":
                    differences.append(f"CHARTç‹€æ…‹ç•°å¸¸: STATUS='{chart_status}' (æ‡‰ç‚º'A')")
            
        except Exception as e:
            differences.append(f"æ¢ä»¶æ¯”å°éŒ¯èª¤: {str(e)}")
        
        return differences
    
    def _analyze_data_group(self, info: Dict[str, Any], trx_results: Dict[str, Any], chart_condition: str, spc_data: Dict[str, Any], factory_config: Dict[str, str]) -> List[str]:
        """åˆ†æDATA_GROUPç›¸é—œå•é¡Œ (æ­¥é©Ÿ16-17)"""
        analysis = []
        factory = info["factory"]
        
        try:
            # æ­¥é©Ÿ 16: æª¢æŸ¥ SPC è³‡æ–™ä¸­çš„ DATA_GROUP æ˜¯å¦å­˜åœ¨æ–¼ MES DB ä¸­
            analysis.append("ğŸ“ **æ­¥é©Ÿ16: æª¢æŸ¥SPCè³‡æ–™ä¸­çš„DATA_GROUPæ˜¯å¦å­˜åœ¨æ–¼MES DB**")
            
            if not spc_data.get("found") or not spc_data.get("data"):
                analysis.append("   âš ï¸ ç„¡SPCè³‡æ–™ï¼Œè·³éDATA_GROUPæª¢æŸ¥")
                return analysis
            
            # å¾SPCè³‡æ–™ä¸­ç²å–DATA_GROUP
            spc_records = spc_data["data"]
            data_groups = set()
            for record in spc_records:
                if isinstance(record, dict) and 'DATA_GROUP' in record:
                    data_groups.add(record['DATA_GROUP'])
            
            if not data_groups:
                analysis.append("   âš ï¸ SPCè³‡æ–™ä¸­ç„¡DATA_GROUPæ¬„ä½")
                return analysis
            
            analysis.append(f"   å¾SPCè³‡æ–™ä¸­æ‰¾åˆ°DATA_GROUP: {list(data_groups)}")
            
            # å¾ Chart_Condition ä¸­æå– MES æŸ¥è©¢æ¢ä»¶
            mes_conditions = self._extract_mes_conditions_from_chart(chart_condition)
            
            if not mes_conditions:
                analysis.append("   âš ï¸ ç„¡æ³•å¾Chart_Conditionä¸­æå–MESæŸ¥è©¢æ¢ä»¶")
                return analysis
            
            analysis.append(f"   å¾Chart_Conditionæå–çš„æ¢ä»¶: {mes_conditions}")
            
            # æª¢æŸ¥æ¯å€‹ DATA_GROUP æ˜¯å¦åœ¨ MES DB ä¸­å­˜åœ¨
            mlitem_table = factory_config.get('mlitem_table', 'AMLITEM')
            mes_schema = factory_config.get('mes_schema', factory_config['data_schema'])
            
            data_group_missing = []
            for data_group in data_groups:
                if not self._is_safe_identifier(str(data_group)):
                    analysis.append(f"   âŒ DATA_GROUPæ ¼å¼ä¸å®‰å…¨: {data_group}")
                    continue
                
                # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
                where_conditions = []
                for key, value in mes_conditions.items():
                    if self._is_safe_identifier(str(value)):
                        where_conditions.append(f"{key} = '{value}'")
                
                where_conditions.append(f"DATA_GROUP = '{data_group}'")
                where_clause = " AND ".join(where_conditions)
                
                sql = f"SELECT * FROM {mes_schema}.{mlitem_table} WHERE {where_clause}"
                
                try:
                    result = execute_query(sql, "MES", factory, limit=1)
                    if result['success'] and result['row_count'] > 0:
                        analysis.append(f"   âœ… DATA_GROUP '{data_group}' åœ¨MES DBä¸­å­˜åœ¨")
                    else:
                        analysis.append(f"   âŒ DATA_GROUP '{data_group}' åœ¨MES DBä¸­ä¸å­˜åœ¨")
                        data_group_missing.append(data_group)
                        
                except Exception as e:
                    analysis.append(f"   âŒ æŸ¥è©¢DATA_GROUP '{data_group}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    data_group_missing.append(data_group)
            
            if data_group_missing:
                analysis.append(f"   âŒ **{mlitem_table} DBç¼ºå°‘è¨­å®šä¸Šå ±DATA_GROUP: {data_group_missing}**")
            
            # æ­¥é©Ÿ 17: æª¢æŸ¥ TRX LOG INPUT ä¸­çš„ data_group æ¨™ç±¤
            analysis.append("")
            analysis.append("ğŸ“ **æ­¥é©Ÿ17: æª¢æŸ¥TRX LOG INPUTä¸­çš„data_groupæ¨™ç±¤**")
            
            trx_data_groups = self._extract_data_groups_from_trx(trx_results)
            
            if not trx_data_groups:
                analysis.append("   âŒ **ç¼ºå°‘å¿…è¦ä¸Šå ±DATA_GROUP** - TRX LOG INPUTä¸­æœªæ‰¾åˆ°data_groupæ¨™ç±¤")
            else:
                analysis.append(f"   å¾TRX LOG INPUTæå–çš„data_group: {trx_data_groups}")
                
                # æ¯”å° SPC å’Œ TRX çš„ DATA_GROUP
                missing_in_trx = data_groups - set(trx_data_groups)
                if missing_in_trx:
                    analysis.append(f"   âŒ **ç¼ºå°‘å¿…è¦ä¸Šå ±DATA_GROUP** - SPCä¸­æœ‰ä½†TRX INPUTä¸­æ²’æœ‰: {list(missing_in_trx)}")
                else:
                    analysis.append("   âœ… TRX LOG INPUTåŒ…å«æ‰€éœ€çš„data_group")
            
        except Exception as e:
            analysis.append(f"   âŒ DATA_GROUPåˆ†æéŒ¯èª¤: {str(e)}")
        
        return analysis
    
    def _extract_mes_conditions_from_chart(self, chart_condition: str) -> Dict[str, str]:
        """å¾Chart_Conditionä¸­æå–MESæŸ¥è©¢æ¢ä»¶"""
        conditions = {}
        
        # æå–å„ç¨®æ¢ä»¶
        patterns = {
            'EQPT_ID': r"EQPT_ID\s*=\s*'([^']+)'",
            'REP_UNIT': r"REP_UNIT\s*=\s*'([^']+)'", 
            'DATA_PAT': r"DATA_PAT\s*=\s*'([^']+)'",
            'MES_ID': r"MES_ID\s*=\s*'([^']+)'"
        }
        
        for field, pattern in patterns.items():
            match = re.search(pattern, chart_condition)
            if match:
                conditions[field] = match.group(1)
        
        return conditions
    
    def _extract_data_groups_from_trx(self, trx_results: Dict[str, Any]) -> List[str]:
        """å¾TRX LOG INPUTä¸­æå–data_groupæ¨™ç±¤æ•¸å€¼"""
        data_groups = []
        
        try:
            detail = trx_results.get("detail", {})
            
            # æŸ¥æ‰¾è¼¸å…¥äº¤æ˜“XML
            input_sources = [
                detail.get('inputTrx', ''),
                detail.get('input_trx', ''),
                detail.get('reqBody', '')
            ]
            
            if 'evntlgDetail' in detail:
                event_detail = detail['evntlgDetail']
                input_sources.extend([
                    event_detail.get('inputTrx', ''),
                    event_detail.get('reqBody', '')
                ])
            
            for input_xml in input_sources:
                if not input_xml:
                    continue
                
                # æŸ¥æ‰¾data_groupæ¨™ç±¤
                data_group_matches = re.findall(r'<data_group[^>]*>([^<]+)</data_group>', input_xml, re.IGNORECASE)
                data_groups.extend(data_group_matches)
                
                # ä¹ŸæŸ¥æ‰¾å¯èƒ½çš„å…¶ä»–æ ¼å¼
                data_group_matches2 = re.findall(r'data_group["\']?\s*[:=]\s*["\']?([^"\'>\s,]+)', input_xml, re.IGNORECASE)
                data_groups.extend(data_group_matches2)
        
        except Exception as e:
            pass
        
        # å»é‡ä¸¦è¿”å›
        return list(set(data_groups))
    
    def _analyze_data_group_basic(self, info: Dict[str, Any], trx_results: Dict[str, Any], spc_data: Dict[str, Any]) -> List[str]:
        """åŸºæœ¬DATA_GROUPæª¢æŸ¥ï¼ˆç•¶ç„¡Chart_Conditionæ™‚ï¼‰"""
        analysis = []
        
        try:
            # æª¢æŸ¥SPCè³‡æ–™ä¸­çš„DATA_GROUP
            analysis.append("ğŸ“ **æª¢æŸ¥SPCè³‡æ–™ä¸­çš„DATA_GROUP**")
            
            if not spc_data.get("found") or not spc_data.get("data"):
                analysis.append("   âš ï¸ ç„¡SPCè³‡æ–™ï¼Œç„¡æ³•æª¢æŸ¥DATA_GROUP")
            else:
                spc_records = spc_data["data"]
                data_groups = set()
                for record in spc_records:
                    if isinstance(record, dict) and 'DATA_GROUP' in record:
                        data_groups.add(record['DATA_GROUP'])
                
                if data_groups:
                    analysis.append(f"   ğŸ“‹ SPCè³‡æ–™ä¸­çš„DATA_GROUP: {list(data_groups)}")
                else:
                    analysis.append("   âš ï¸ SPCè³‡æ–™ä¸­ç„¡DATA_GROUPæ¬„ä½")
            
            # æª¢æŸ¥TRX LOG INPUTä¸­çš„data_group
            analysis.append("")
            analysis.append("ğŸ“ **æª¢æŸ¥TRX LOG INPUTä¸­çš„data_groupæ¨™ç±¤**")
            
            trx_data_groups = self._extract_data_groups_from_trx(trx_results)
            
            if not trx_data_groups:
                analysis.append("   âŒ **ç¼ºå°‘å¿…è¦ä¸Šå ±DATA_GROUP** - TRX LOG INPUTä¸­æœªæ‰¾åˆ°data_groupæ¨™ç±¤")
            else:
                analysis.append(f"   âœ… TRX LOG INPUTä¸­çš„data_group: {trx_data_groups}")
                
                # å¦‚æœæœ‰SPCè³‡æ–™ï¼Œé€²è¡Œç°¡å–®æ¯”å°
                if spc_data.get("found") and spc_data.get("data"):
                    spc_records = spc_data["data"]
                    spc_data_groups = set()
                    for record in spc_records:
                        if isinstance(record, dict) and 'DATA_GROUP' in record:
                            spc_data_groups.add(record['DATA_GROUP'])
                    
                    if spc_data_groups:
                        missing_in_trx = spc_data_groups - set(trx_data_groups)
                        if missing_in_trx:
                            analysis.append(f"   âš ï¸ SPCä¸­æœ‰ä½†TRX INPUTä¸­æ²’æœ‰çš„data_group: {list(missing_in_trx)}")
                        else:
                            analysis.append("   âœ… TRX LOG INPUTåŒ…å«SPCæ‰€éœ€çš„data_group")
            
        except Exception as e:
            analysis.append(f"   âŒ åŸºæœ¬DATA_GROUPæª¢æŸ¥éŒ¯èª¤: {str(e)}")
        
        return analysis
    
    def _format_trx_details(self, trx_results: Dict) -> List[str]:
        """æ ¼å¼åŒ–TRX LOGè©³ç´°è³‡æ–™"""
        details = []
        
        if not trx_results.get("success") or 'detail' not in trx_results:
            return details
        
        detail = trx_results['detail']
        
        # åŸºæœ¬è³‡è¨Šè¡¨æ ¼
        details.append("### ğŸ“‹ TRX LOG åŸºæœ¬è³‡è¨Š")
        details.append("")
        details.append("| é …ç›® | å€¼ |")
        details.append("|------|-----|")
        
        # å˜—è©¦å¾ä¸åŒå¯èƒ½çš„è³‡æ–™çµæ§‹ä¸­æå–è³‡è¨Š
        basic_info = {}
        
        # å¦‚æœdetailæ˜¯å­—å…¸ä¸”åŒ…å«evntlgDetail
        if isinstance(detail, dict) and 'evntlgDetail' in detail:
            event_detail = detail['evntlgDetail']
            basic_info = {
                'æ™‚é–“æˆ³è¨˜': event_detail.get('tStamp', trx_results.get('t_stamp', 'N/A')),
                'è¨­å‚™ID': event_detail.get('eqptId', 'N/A'),
                'ç»ç’ƒID': event_detail.get('shtId', 'N/A'),
                'è¼‰ç›¤ID': event_detail.get('crrId', 'N/A'),
                'éŒ¯èª¤ç¢¼': event_detail.get('errcode', 'N/A'),
                'è™•ç†æ™‚é–“': f"{event_detail.get('procTime', 'N/A')}ms" if event_detail.get('procTime') != 'N/A' else 'N/A'
            }
        # å¦‚æœdetailç›´æ¥åŒ…å«é€™äº›æ¬„ä½
        elif isinstance(detail, dict):
            basic_info = {
                'æ™‚é–“æˆ³è¨˜': detail.get('tStamp', trx_results.get('t_stamp', 'N/A')),
                'è¨­å‚™ID': detail.get('eqptId', 'N/A'),
                'ç»ç’ƒID': detail.get('shtId', 'N/A'),
                'è¼‰ç›¤ID': detail.get('crrId', 'N/A'),
                'éŒ¯èª¤ç¢¼': detail.get('errcode', 'N/A'),
                'è™•ç†æ™‚é–“': f"{detail.get('procTime', 'N/A')}ms" if detail.get('procTime') != 'N/A' else 'N/A'
            }
        
        # å¦‚æœéƒ½æ²’æœ‰ï¼Œå¾TRX resultsæœ¬èº«ç²å–
        if all(v == 'N/A' for v in basic_info.values()):
            basic_info = {
                'æ™‚é–“æˆ³è¨˜': trx_results.get('t_stamp', 'N/A'),
                'è¨­å‚™ID': 'N/A',
                'ç»ç’ƒID': 'N/A', 
                'è¼‰ç›¤ID': 'N/A',
                'éŒ¯èª¤ç¢¼': 'N/A',
                'è™•ç†æ™‚é–“': 'N/A'
            }
        
        for field_name, value in basic_info.items():
            details.append(f"| {field_name} | {value} |")
        
        details.append("")
        
        # è¼¸å…¥äº¤æ˜“XML (æ ¼å¼åŒ–)
        input_trx = None
        if isinstance(detail, dict):
            # å˜—è©¦ä¸åŒçš„æ¬„ä½åç¨±
            input_trx = detail.get('inputTrx') or detail.get('input_trx') or detail.get('reqBody')
            if 'evntlgDetail' in detail:
                event_detail = detail['evntlgDetail']
                input_trx = input_trx or event_detail.get('inputTrx') or event_detail.get('reqBody')
        
        if input_trx:
            details.append("### ğŸ“¥ è¼¸å…¥äº¤æ˜“ XML")
            details.append("```xml")
            details.append(self._format_xml_pretty(input_trx))
            details.append("```")
            details.append("")
        
        # è¼¸å‡ºäº¤æ˜“XML
        output_trx = None
        if isinstance(detail, dict):
            # å˜—è©¦ä¸åŒçš„æ¬„ä½åç¨±
            output_trx = detail.get('outputTrx') or detail.get('output_trx') or detail.get('rspBody')
            if 'evntlgDetail' in detail:
                event_detail = detail['evntlgDetail']
                output_trx = output_trx or event_detail.get('outputTrx') or event_detail.get('rspBody')
        
        if output_trx:
            details.append("### ğŸ“¤ è¼¸å‡ºäº¤æ˜“ XML")
            details.append("```xml") 
            details.append(self._format_xml_pretty(output_trx))
            details.append("```")
            details.append("")
        
        return details
    
    def _format_spc_details(self, spc_data: List[Dict]) -> List[str]:
        """æ ¼å¼åŒ–SPCè³‡æ–™åº«è©³ç´°è³‡æ–™"""
        details = []
        
        if not spc_data:
            return details
        
        details.append("### ğŸ“Š SPC è³‡æ–™åº«è©³ç´°è¨˜éŒ„")
        details.append("")
        
        for i, record in enumerate(spc_data):
            details.append(f"#### ğŸ“‹ ç¬¬{i+1}ç­†è¨˜éŒ„")
            details.append("")
            details.append("| æ¬„ä½åç¨± | å€¼ |")
            details.append("|----------|-----|")
            
            # é‡è¦æ¬„ä½å„ªå…ˆé¡¯ç¤º
            important_fields = [
                ('åŸºæœ¬è³‡è¨Š', ['T_STAMP', 'SHT_ID', 'LOT_ID', 'CRR_ID', 'PRODUCT_ID']),
                ('è¨­å‚™è³‡è¨Š', ['EQPT_ID', 'ONCHID', 'CLDATE', 'CLTIME', 'PROC_ID']),
                ('æ•¸å€¼è³‡è¨Š', ['DTX', 'USPEC', 'LSPEC', 'TARGET', 'UCL1', 'LCL1']),
                ('ç‹€æ…‹è³‡è¨Š', ['OOS', 'OOC1', 'OOC2', 'OOC3', 'DELFLG', 'DATA_GROUP'])
            ]
            
            for category, fields in important_fields:
                details.append(f"| **{category}** | |")
                for field in fields:
                    if field in record:
                        value = record[field]
                        if value is None:
                            value = 'NULL'
                        elif isinstance(value, (int, float)):
                            value = str(value)
                        elif isinstance(value, str):
                            # æˆªæ–·éé•·çš„å­—ä¸²
                            value = value[:50] + "..." if len(value) > 50 else value
                        details.append(f"| {field} | {value} |")
            
            details.append("")
            
            # å¦‚æœæœ‰å¤šç­†è¨˜éŒ„ï¼Œåœ¨è¨˜éŒ„é–“åŠ åˆ†éš”ç·š
            if i < len(spc_data) - 1:
                details.append("---")
                details.append("")
        
        return details
    
    def _format_xml_pretty(self, xml_content: str) -> str:
        """ç¾åŒ–XMLæ ¼å¼"""
        try:
            import xml.etree.ElementTree as ET
            import re
            
            # æ¸…ç†XMLå…§å®¹
            xml_content = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x84\x86-\x9f]', '', xml_content)
            
            # è§£æXML
            root = ET.fromstring(xml_content)
            
            # ç¾åŒ–æ ¼å¼
            def indent_xml(elem, level=0):
                indent_str = "\n" + level * "  "
                if len(elem):
                    if not elem.text or not elem.text.strip():
                        elem.text = indent_str + "  "
                    if not elem.tail or not elem.tail.strip():
                        elem.tail = indent_str
                    for child in elem:
                        indent_xml(child, level + 1)
                    if not child.tail or not child.tail.strip():
                        child.tail = indent_str
                else:
                    if level and (not elem.tail or not elem.tail.strip()):
                        elem.tail = indent_str
            
            indent_xml(root)
            return ET.tostring(root, encoding='unicode')
            
        except Exception as e:
            # å¦‚æœXMLè§£æå¤±æ•—ï¼Œè¿”å›åŸå§‹å…§å®¹
            return xml_content


