"""
èŠå¤©å·¥å…·å‡½æ•¸
"""

from typing import Dict, Any, List
import re
from datetime import datetime

def format_message(content: str, role: str = "assistant") -> str:
    """
    æ ¼å¼åŒ–è¨Šæ¯å…§å®¹
    
    Args:
        content: è¨Šæ¯å…§å®¹
        role: è§’è‰²é¡å‹
        
    Returns:
        æ ¼å¼åŒ–å¾Œçš„è¨Šæ¯
    """
    # æ·»åŠ æ™‚é–“æˆ³è¨˜
    timestamp = datetime.now().strftime("%H:%M")
    
    if role == "user":
        return f"[{timestamp}] ğŸ‘¤ {content}"
    else:
        return f"[{timestamp}] ğŸ¤– {content}"

def extract_keywords(text: str) -> List[str]:
    """å¾æ–‡å­—ä¸­æå–é—œéµå­—"""
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œç‰¹æ®Šå­—ç¬¦
    clean_text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
    
    # åˆ†å‰²æˆè©èª
    words = clean_text.split()
    
    # éæ¿¾çŸ­è©å’Œå¸¸è¦‹è©
    stopwords = {'çš„', 'æ˜¯', 'åœ¨', 'äº†', 'æœ‰', 'å’Œ', 'èˆ‡', 'æˆ–', 'ä½†æ˜¯', 'ç„¶è€Œ', 'å› ç‚º', 'æ‰€ä»¥', 'é€™', 'é‚£', 'ä»€éº¼', 'å¦‚ä½•', 'ç‚ºä»€éº¼'}
    keywords = [word for word in words if len(word) > 1 and word not in stopwords]
    
    return list(set(keywords))[:10]  # è¿”å›å‰10å€‹å»é‡çš„é—œéµå­—

def calculate_similarity(text1: str, text2: str) -> float:
    """
    è¨ˆç®—å…©å€‹æ–‡å­—çš„ç°¡å–®ç›¸ä¼¼åº¦
    
    Args:
        text1: æ–‡å­—1
        text2: æ–‡å­—2
        
    Returns:
        ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
    """
    keywords1 = set(extract_keywords(text1))
    keywords2 = set(extract_keywords(text2))
    
    if not keywords1 or not keywords2:
        return 0.0
    
    intersection = keywords1.intersection(keywords2)
    union = keywords1.union(keywords2)
    
    return len(intersection) / len(union) if union else 0.0

def truncate_text(text: str, max_length: int = 100) -> str:
    """
    æˆªæ–·æ–‡å­—åˆ°æŒ‡å®šé•·åº¦
    
    Args:
        text: è¦æˆªæ–·çš„æ–‡å­—
        max_length: æœ€å¤§é•·åº¦
        
    Returns:
        æˆªæ–·å¾Œçš„æ–‡å­—
    """
    if len(text) <= max_length:
        return text
    
    return text[:max_length-3] + "..."

def format_confidence(confidence: float) -> str:
    """
    æ ¼å¼åŒ–ä¿¡å¿ƒåº¦é¡¯ç¤º
    
    Args:
        confidence: ä¿¡å¿ƒåº¦åˆ†æ•¸ (0-1)
        
    Returns:
        æ ¼å¼åŒ–çš„ä¿¡å¿ƒåº¦å­—ç¬¦ä¸²
    """
    if confidence >= 0.8:
        return f"ğŸŸ¢ é«˜ä¿¡å¿ƒåº¦ ({confidence:.1%})"
    elif confidence >= 0.5:
        return f"ğŸŸ¡ ä¸­ç­‰ä¿¡å¿ƒåº¦ ({confidence:.1%})"
    else:
        return f"ğŸ”´ ä½ä¿¡å¿ƒåº¦ ({confidence:.1%})"

def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æª”åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦
    
    Args:
        filename: åŸå§‹æª”å
        
    Returns:
        æ¸…ç†å¾Œçš„æª”å
    """
    # ç§»é™¤æˆ–æ›¿æ›ä¸å®‰å…¨å­—ç¬¦
    unsafe_chars = r'<>:"/\|?*'
    for char in unsafe_chars:
        filename = filename.replace(char, '_')
    
    return filename.strip()

def parse_query_intent(query: str) -> Dict[str, Any]:
    """
    åˆ†ææŸ¥è©¢æ„åœ–
    
    Args:
        query: ç”¨æˆ¶æŸ¥è©¢
        
    Returns:
        æ„åœ–åˆ†æçµæœ
    """
    query_lower = query.lower()
    
    intent = {
        "type": "general",
        "keywords": extract_keywords(query),
        "is_question": False,
        "is_calculation": False,
        "is_search": False,
        "requires_images": False
    }
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºå•é¡Œ
    question_patterns = [r'ä»€éº¼', r'å¦‚ä½•', r'æ€éº¼', r'ç‚ºä»€éº¼', r'å“ªè£¡', r'èª°', r'ä½•æ™‚', r'\?']
    intent["is_question"] = any(re.search(pattern, query_lower) for pattern in question_patterns)
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºè¨ˆç®—
    calc_patterns = [r'\d+\s*[\+\-\*\/]\s*\d+', r'è¨ˆç®—', r'ç®—']
    intent["is_calculation"] = any(re.search(pattern, query_lower) for pattern in calc_patterns)
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºæœå°‹
    search_patterns = [r'æœå°‹', r'æŸ¥æ‰¾', r'æ‰¾', r'é¡¯ç¤º']
    intent["is_search"] = any(re.search(pattern, query_lower) for pattern in search_patterns)
    
    # åˆ¤æ–·æ˜¯å¦éœ€è¦åœ–ç‰‡
    image_patterns = [r'åœ–ç‰‡', r'åœ–åƒ', r'ç…§ç‰‡', r'æˆªåœ–', r'åœ–']
    intent["requires_images"] = any(re.search(pattern, query_lower) for pattern in image_patterns)
    
    return intent
